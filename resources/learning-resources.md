### 分类整理

1. **综合教程与课程（理论+实践）**
    
    1. **[动手学大模型应用开发](https://datawhalechina.github.io/llm-universe/#/)**: Datawhale的开源教程，覆盖大模型基础、开发与应用，适合初学者系统学习。
        
    2. **[Large Language Models (LLMs) with Colab notebooks](https://mlabonne.github.io/blog/)**: 提供Colab笔记本，边学边练，适合动手实践。
        
    3. **[AI-Guide-and-Demos](https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN)**: 中文AI指南与代码示例，适合中文用户快速上手。
        
    4. **[LLM-Action](https://github.com/liguodongiot/llm-action)**: 聚焦大模型实战项目，适合进阶开发者。
        
2. **视频资源（B站/YTB）**
    
    1. B站：**[五里墩茶社](https://space.bilibili.com/615957867)**、**[木羽Cheney](https://space.bilibili.com/3537113897241540)**、**[漆妮妮](https://space.bilibili.com/1262370256)**、[TechBeat人工智能社区](https://space.bilibili.com/209732435)等，内容涵盖大模型基础、算法解析和项目实战，适合初学者和爱好者。
        
    2. YouTube：**[AI Anytime](https://www.youtube.com/channel/UC-zVytOQB62OwMhKRi0TDvg)**、**[AI超元域](https://www.youtube.com/@AIsuperdomain)**、**[IBM Technology](https://www.youtube.com/@IBMTechnology)**，提供英文内容，适合了解国际前沿动态。
        
    3. **[Unify Reading Paper Group](https://www.youtube.com/playlist?list=PLwNuX3xB_tv91QvDXlW2TjrLGHW51uMul)**：论文解读，适合深入研究大模型理论。
        
3. **博客与文章（深入理论与实践）**
    
    1. **[Huggingface Blog](https://huggingface.co/blog/zh)**：提供大模型工具、框架和案例，适合开发者参考。
        
    2. **[Lil’Log (OponAI)](https://lilianweng.github.io/)**：OpenAI研究员博客，深入解析大模型技术，适合进阶学习。
        
    3. **[科学空间（苏剑林）](https://kexue.fm/)**：中文AI博客，理论与代码结合，适合国内开发者。
        
    4. **[Chip Huyen](https://huyenchip.com/blog/)**、**[mlabonne](https://mlabonne.github.io/blog/)**：英文博客，分享大模型开发经验与趋势。
        
4. **Prompt工程与可视化**
    
    1. **[Prompt Engineering Guide](https://www.promptingguide.ai/)**：Prompt设计的最佳实践，适合优化大模型交互。
        
    2. **[LLM Visualization](https://bbycroft.net/llm)**：大模型结构可视化，助力理解Transformer等核心概念。
        
5. **进阶与实战工具**
    
    1. **[How Much VRAM](https://github.com/AlexBodner/How_Much_VRAM)**：帮助评估大模型训练的显存需求，适合硬件选型。
        
    2. **[Implementation of all RAG techniques](https://github.com/FareedKhan-dev/all-rag-techniques)**：RAG（检索增强生成）技术实现，适合开发知识密集型应用。
        
    3. **[W&B articles](https://wandb.ai/fully-connected)**：Weights & Biases的文章，分享模型训练与调优技巧。
        
6. **理论书籍与资源**
    
    1. **[Theoretical Machine Learning: A Handbook for Everyone](https://www.tengjiaye.com/mlbook.html)**：机器学习理论手册，适合打牢基础。
        

  

### 学习建议

- **零基础入门**：从[动手学大模型应用开发]和B站视频（如五里墩茶社、漆妮妮）开始，结合Colab笔记本实践。
    
- **进阶开发**：深入[Huggingface Blog]、[Lil’Log]，并尝试[LLM-Action]和[Implementation of all RAG techniques]的实战项目。
    
- **优化Prompt**：参考[Prompt Engineering Guide]，提升模型交互效果。
    
- **硬件与资源管理**：用[How Much VRAM]评估显存需求，结合[W&B articles]优化训练流程。
    
- **持续跟踪前沿**：关注[Unify Reading Paper Group]和[Chip Huyen]，了解最新论文与趋势。
    

  

### 补充资源

- **[DeepLearning.AI](https://www.deeplearning.ai/)**：提供大模型与AI开发的免费/付费课程，Andrew Ng团队出品。
    
- **[Fast.ai](https://www.fast.ai/)**：实用深度学习课程，适合快速上手。
    
- **[GitHub Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)**：大模型资源合集，包含论文、工具和数据集。
  

## 全面总结：大模型学习资源

### 1. 大学课程

#### 斯坦福大学

- **CS25: Transformers United V5 (2025)**
    - **内容**：探讨Transformer最新突破，邀请Google DeepMind的Denny Zhou、OpenAI的Karina Nguyen、Hongyu Ren及Meta的Andrew Brown等讲者。
    - **形式**：免费开放，现场旁听或Zoom直播（每周二太平洋夏令时间15:00-16:20，北京时间周三06:00-07:20），视频上传至YouTube。
    - **资源**：https://web.stanford.edu/class/cs25/, 第一期视频：https://www.youtube.com/watch?v=JKbtWimlzAE
    - **评价**：前沿性强，适合跟踪最新研究动态，适合中高级学习者。

- **CS25: Transformers United (往期)**
    - **V2 - Geoffrey Hinton: Representing Part-Whole Hierarchies**：提出GLOM模型，增强Transformer视觉任务表现，探讨自注意力机制瓶颈。
        - 链接：https://www.youtube.com/watch?v=CYaju6aCMoQ
        - 评价：★★★★☆，适合复习Transformer理论局限及视觉领域扩展。
    - **V2 - Andrej Karpathy: Introduction to Transformers**：系统讲解自注意力、多头注意力及Vision Transformer。
        - 链接：https://www.youtube.com/watch?v=XfpMkf4rD6E
        - 评价：★★★★★，入门必看，简洁清晰，适合初学者快速掌握Transformer核心。
    - **V3 - Douwe Kiela: Retrieval Augmented Language Models**：深入RAG技术，分析其解决幻觉和时效性问题的潜力。
        - 链接：https://www.youtube.com/watch?v=mE7IDf2SmJg
        - 评价：★★★★☆，复习RAG的绝佳资源，适合有基础的学习者。
    - **V4 - Jason Wei & Hyung Won Chung**：探讨LLM直观理解、扩展律及Transformer多模态潜力。
        - 评价：内容深入，适合中高级学习者复习LLM理论。

- **CS224N: Natural Language Processing with Deep Learning**
    - **内容**：全面NLP课程，覆盖深度学习技术及LLM。
    - **链接**：https://web.stanford.edu/class/cs224n/
    - **评价**：系统性强，适合中高级学习者深入学习NLP。

- **CS324: Large Language Models**
    - **内容**：LLM进阶研究。
    - **链接**：https://stanford-cs324.github.io/winter2022/
    - **评价**：适合研究导向的学习者，内容偏学术。

#### 卡内基梅隆大学

- **11-711 ANLP: Advanced Natural Language Processing**
    - **内容**：涵盖语言模型、序列建模、Transformer、提示与微调，提供课件下载。
    - **链接**：https://phontron.com/class/anlp2024/lectures/
    - **评价**：内容全面，适合中高级学习者复习NLP核心技术。

#### 其他大学

- **普林斯顿 COS 597G (2022): Understanding Large Language Models**
    - **链接**：https://www.cs.princeton.edu/courses/archive/fall22/cos597G/
    - **评价**：理论性强，适合学术研究者。
- **约翰霍普金斯 CS 601.471/671: NLP: Self-supervised Models**
    - **链接**：https://self-supervised.cs.jhu.edu/sp2023/index.html
    - **评价**：专注自监督学习，适合中高级学习者。
- **滑铁卢大学 CS 886: Recent Advances on Foundation Models**
    - **链接**：https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/
    - **评价**：聚焦前沿基础模型，适合研究者。
- **台湾大学 Introduction to Generative AI (2024)**
    - **讲者**：李宏毅
    - **链接**：https://speech.ee.ntu.edu.tw/~hylee/genai/2024 spring.php
    - **评价**：内容生动，适合中级学习者了解生成式AI。
- **密歇根大学 LLMs and Transformers (2024)**
    - **链接**：https://www.ambujtewari.com/LLM-fall2024/
    - **评价**：学术与实践结合，适合中高级学习者。

### 2. 在线课程与教程

#### DeepLearning.AI

- **Generative AI for Everyone (吴恩达)**
    - **内容**：生成式AI入门，介绍大模型概念与应用。
    - **链接**：https://www.deeplearning.ai/courses/generative-ai-for-everyone/
    - **评价**：★★★★☆，入门必看，通俗易懂，适合零基础学习者。
- **LLM Series (吴恩达)**
    - **内容**：全面LLM培训。
    - **链接**：https://learn.deeplearning.ai/
    - **评价**：内容丰富，适合中级学习者。
- **Getting Started with Mistral**
    - **链接**：https://www.deeplearning.ai/short-courses/getting-started-with-mistral/
    - **评价**：实践性强，适合Mistral模型开发者。
- **Knowledge Graphs for RAG**
    - **链接**：https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/
    - **评价**：★★★★☆，复习RAG进阶应用的优质资源。
- **Multimodal RAG: Chat with Videos**
    - **链接**：https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/
    - **评价**：聚焦多模态RAG，适合中高级开发者。

#### OpenAI

- **OpenAI Academy**
    - **内容**：免费AI课程与社区，提供《提示词大师课》等，包含实时互动活动（仅英文）。
    - **链接**：https://academy.openai.com/public/events
    - **评价**：社区驱动，适合实践者与同行交流。
- **OpenAI Cookbook**
    - **内容**：OpenAI API使用示例。
    - **链接**：https://github.com/openai/openai-cookbook
    - **评价**：实用性强，适合API开发者。

#### Hugging Face

- **NLP Course**
    - **内容**：Transformer在NLP中的应用，包含代码示例。
    - **链接**：https://huggingface.co/learn/nlp-course/chapter1/1
    - **评价**：★★★★☆，入门必看，实践性强，适合有编程基础的初学者。
- **AI Agents Course**
    - **链接**：https://github.com/huggingface/agents-course
    - **评价**：适合开发AI代理的实践者。
- **Hugging Face Learn**
    - **链接**：https://huggingface.co/learn
    - **评价**：资源丰富，适合各阶段学习者。

#### 微软

- **Generative AI for Beginners**
    - **链接**：https://github.com/microsoft/generative-ai-for-beginners
    - **评价**：适合初学者，内容简洁。
- **State of GPT**
    - **链接**：https://www.youtube.com/watch?v=bZQun8Y4L2A
    - **评价**：GPT技术概览，适合快速了解。

#### 其他

- **Coursera: Prompt Engineering for ChatGPT**
    - **链接**：https://www.coursera.org/learn/prompt-engineering
    - **评价**：提示工程入门，适合实践者。
- **Cohere LLM University**
    - **链接**：https://cohere.com/llmu
    - **评价**：聚焦嵌入技术，适合开发者。
- **Weights & Biases AI Academy**
    - **链接**：https://www.wandb.courses/pages/w-b-courses
    - **评价**：涵盖微调与LLMOps，适合中高级开发者。
- **Comet: LLM Evaluation**
    - **链接**：https://www.comet.com/site/llm-course/
    - **评价**：LLM评估的系统课程，适合研究者。
- **Anthropic: Prompt Engineering Interactive Tutorial**
    - **链接**：https://github.com/anthropics/courses
    - **评价**：交互式学习，适合提示工程实践。
- **Google: Generative AI for Developers**
    - **链接**：https://www.cloudskillsboost.google/paths/183
    - **评价**：进阶开发者课程，内容深入。

### 3. 开源资源与教程

- **Andrej Karpathy**
    - **Neural Networks: Zero to Hero**：神经网络与LLM系列。
        - 链接：https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ
        - 评价：★★★★★，入门与复习必看，理论实践兼备。
    - **Build nanoGPT**：从头构建GPT模型。
        - 链接：https://github.com/karpathy/build-nanogpt
        - 评价：实践性强，适合动手学习。
    - **LLM101n: Let’s Build a Storyteller**：LLM开发实践。
        - 链接：https://github.com/karpathy/LLM101n
        - 评价：适合中级开发者。
    - **Deep Dive into LLMs like ChatGPT**：LLM深入讲解。
        - 链接：https://www.youtube.com/watch?v=7xTGNNLPyMI
        - 评价：内容全面，适合复习。
- **Mistral AI Cookbook**：Mistral模型使用指南。
    - **链接**：https://github.com/mistralai/cookbook
    - **评价**：适合Mistral开发者。
- **LangGPT**：提示工程学习。
    - **链接**：https://github.com/langgptai/LangGPT
    - **评价**：提示工程实践资源。
- **LLMs From Scratch (Datawhale)**：从零构建LLM。
    - **链接**：https://github.com/datawhalechina/llms-from-scratch-cn
    - **评价**：适合中文学习者实践。
- **Hands-on LLMs**：金融顾问LLM开发。
    - **链接**：https://github.com/iusztinpaul/hands-on-llms
    - **评价**：应用驱动，适合开发者。
- **LLM Interview Notes**：LLM面试技术准备。
    - **链接**：https://github.com/wdndev/llm_interview_note
    - **评价**：适合求职者。
- **LLM Technical Primer**：LLM概念科普。
    - **链接**：https://github.com/karminski/one-small-step
    - **评价**：适合初学者快速了解。
- **LLMsBook**：LLM资源集合。
    - **链接**：https://github.com/liucongg/LLMsBook
    - **评价**：资源全面，适合查阅。

### 4. 专题资源

- **RAG（检索增强生成）**
    - **ACL 2023 Tutorial**：https://acl2023-retrieval-lm.github.io/
    - **Learn RAG From Scratch**：https://www.youtube.com/watch?v=sVcwVQRHIc8
    - **RAG++: From POC to Production**：https://www.wandb.courses/courses/rag-in-production
    - **OpenRAG**：https://openrag.notion.site/Open-RAG-c41b2a4dcdea4527a7c1cd998e763595
    - **评价**：RAG是LLM应用热点，适合中高级学习者深入学习。
- **扩散模型**：
    - **讲义**：https://www.dropbox.com/scl/fi/gmwhx7jfi2nvm8pudn5it/lecture_diffusion_models.pdf
    - **评价**：适合生成模型研究者。
- **视觉Transformer**：
    - **Smol Vision**：https://github.com/merveenoyan/smol-vision
    - **评价**：适合视觉模型开发者。
- **交互式可视化**：
    - **Transformer Explainer**：https://poloclub.github.io/transformer-explainer/
    - **评价**：直观理解Transformer，适合初学者。

### 5. 社区与中文资源

- **清华大学NLP公开课（刘知远团队）**
    - **内容**：大模型原理、微调及中文NLP应用。
    - **链接**：https://www.bilibili.com/video/BV1UG411p7zv/
    - **评价**：★★★★☆，中文学习者复习必看，内容本地化。
- **PromptEngineering.org**：提示工程资源。
    - **链接**：https://promptengineering.org/
    - **评价**：适合实践者。
- **LLM Agents Course**：LLM代理开发。
    - **链接**：https://llmagents-learning.org/f24
    - **评价**：适合前沿应用开发者。

---

## 入门与复习必看课程

### 入门必看

1. **Andrej Karpathy - Neural Networks: Zero to Hero**
    - **理由**：从零讲解神经网络到LLM，理论与代码结合，教学生动。
    - **适合**：零基础或有编程背景的初学者。
    - **链接**：https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ
2. **DeepLearning.AI - Generative AI for Everyone**
    - **理由**：吴恩达主讲，通俗易懂，适合非技术背景者快速了解AI。
    - **适合**：完全零基础学习者。
    - **链接**：https://www.deeplearning.ai/courses/generative-ai-for-everyone/
3. **Hugging Face - NLP Course**
    - **理由**：实践导向，结合Hugging Face工具，快速上手NLP任务。
    - **适合**：有Python基础的初学者。
    - **链接**：https://huggingface.co/learn/nlp-course/chapter1/1
4. **斯坦福 CS25 V2 - Andrej Karpathy: Introduction to Transformers**
    - **理由**：40分钟精炼讲解Transformer核心，权威且清晰。
    - **适合**：初学者快速掌握注意力机制。
    - **链接**：https://www.youtube.com/watch?v=XfpMkf4rD6E

### 复习必看

1. **斯坦福 CS25 V2 - Geoffrey Hinton: Representing Part-Whole Hierarchies**
    - **理由**：Hinton的GLOM模型提供Transformer局限性与未来方向的洞见。
    - **适合**：有基础的学习者梳理理论。
    - **链接**：https://www.youtube.com/watch?v=CYaju6aCMoQ
2. **斯坦福 CS25 V3 - Douwe Kiela: Retrieval Augmented Language Models**
    - **理由**：系统讲解RAG，涵盖理论与最新架构，巩固应用知识。
    - **适合**：熟悉Transformer的学习者。
    - **链接**：https://www.youtube.com/watch?v=mE7IDf2SmJg
3. **清华大学NLP公开课（刘知远团队）**
    - **理由**：中文讲解，覆盖大模型全貌及中文应用，适合本地化复习。
    - **适合**：中文背景的学习者。
    - **链接**：https://www.bilibili.com/video/BV1UG411p7zv/
4. **DeepLearning.AI - Knowledge Graphs for RAG**
    - **理由**：聚焦RAG进阶应用，理论与实践结合。
    - **适合**：熟悉RAG的学习者。
    - **链接**：https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/

---

## 学习路径建议

### 入门路径（1-2个月）

1. **概念入门**：学习《Generative AI for Everyone》（1周），快速了解大模型全貌。
2. **Transformer基础**：观看《Andrej Karpathy - Introduction to Transformers》（1天），掌握自注意力机制。
3. **实践上手**：通过《Hugging Face - NLP Course》训练简单模型（2-3周）。
4. **深入代码**：完成《Andrej Karpathy - Build nanoGPT》，从头实现GPT（2-3周）。

### 复习路径（1个月）

1. **理论梳理**：重温《Geoffrey Hinton - Representing Part-Whole Hierarchies》（1天），理解Transformer局限性。
2. **RAG巩固**：学习《Douwe Kiela - Retrieval Augmented Language Models》和《Knowledge Graphs for RAG》（1-2周）。
3. **中文视角**：复习《清华大学NLP公开课》，梳理本地化应用（1周）。
4. **前沿跟踪**：关注CS25 V5最新讲座（https://web.stanford.edu/class/cs25/），了解2025年进展。

### 其他建议

- **实践驱动**：利用nanoGPT、LLMs From Scratch等项目进行开发实践。
- **社区参与**：加入OpenAI Academy或Hugging Face社区，与专家交流。
- **持续学习**：定期关注DeepLearning.AI、斯坦福CS25等平台更新。