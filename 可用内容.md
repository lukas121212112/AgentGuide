# å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å­¦ä¹ è·¯çº¿å›¾

## ç§‘ç­è·¯çº¿ï¼ˆç¨³æ‰ç¨³æ‰“ï¼‰

![](https://ccn7vpu5l5y8.feishu.cn/space/api/box/stream/download/asynccode/?code=ZDg4OGI5M2FhMjk3NWRlMTYwYjI2ZGEyNzQ0NDA1MzNfRm5zRXptczcyOHVVZVRNa2lCczB0dmVjNXdOaW9mTXpfVG9rZW46QTF1N2JVcjNGb1I2d014d0NMU2NqWFNvblBoXzE3NjIzNDY5NDI6MTc2MjM1MDU0Ml9WNA)

### **æ­¥éª¤1:** **æœºå™¨å­¦ä¹ ****åŸºç¡€**

1. **å¤ä¹ ****çº¿æ€§ä»£æ•°****ä¸æ¦‚ç‡**
    

å­¦ä¹ çº¿æ€§ä»£æ•°ï¼ˆå‘é‡ã€çŸ©é˜µã€è¿ç®—ï¼‰å’Œæ¦‚ç‡è®ºçš„åŸºç¡€çŸ¥è¯†ã€‚

**èµ„æº**ï¼š

1. DeepLearning.AI æ¨å‡ºçš„ Mathematics for Machine Learning and Data Science ä¸“é¡¹è¯¾ç¨‹ Probability & Statistics for Machine Learning and Data Science _è™½ç„¶å£éŸ³æœ‰ç‚¹é‡ï¼Œä½†æ˜¯çœŸçš„å®¹æ˜“ç†è§£_ https://www.bilibili.com/video/BV1Fo4y1N7AX?p=1&vd_source=e1382be5be85cdcfd0d80d83c7c62002 ã€æ¬è¿è‡ªCourseraã€‘
    
2. Essence of Linear Algebra éå¸¸å®¹æ˜“ç†è§£çš„çŸ­ç‰‡ç³»åˆ— https://www.bilibili.com/video/BV1u4411H7Ry/?vd_source=e1382be5be85cdcfd0d80d83c7c62002 ã€æ¬è¿è‡ªæ²¹ç®¡ã€‘
    
3. å¯æ±—æ¦‚ç‡å­¦é™¢ï¼šhttps://www.khanacademy.org/math/statistics-probability
    
4. çº¿æ€§ä»£æ•°å¯æ±—å­¦é™¢ï¼šhttps://www.khanacademy.org/math/linear-algebra
    

  

5. **Pythonç¼–ç¨‹åŸºç¡€**

å¦‚æœä½ è¿˜æ²¡æœ‰ç†Ÿæ‚‰Pythonï¼Œè¯·ç†Ÿæ‚‰å®ƒï¼Œå› ä¸ºå®ƒå¹¿æ³›ç”¨äºMLã€‚

**å…³é”®åº“**ï¼šNumPyã€Pandasã€Matplotlibã€‚

**èµ„æº**ï¼š

1. Bill Lubanovic çš„ã€ŠIntroducing Pythonã€‹
    
2. Python.orgæ•™ç¨‹ï¼šhttps://docs.python.org/3/tutorial/index.html
    
3. W3School Pythonæ•™ç¨‹ï¼šhttps://www.w3schools.com/python/
    

_Pythonçš„ç½‘ä¸Šèµ„æºéå¸¸çš„å¤šï¼Œè¿™é‡Œå°±ä¸ä¸€ä¸€èµ˜è¿°äº†ã€‚_

  

3. **æœºå™¨å­¦ä¹ ****å¯¼è®º**
    

- ä»åŸºæœ¬çš„æœºå™¨å­¦ä¹ æ¦‚å¿µå¼€å§‹ï¼Œå¦‚ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ã€‚
    
- äº†è§£çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€Kè¿‘é‚»å’Œå†³ç­–æ ‘ç­‰å…³é”®ç®—æ³•ã€‚
    

**èµ„æº**ï¼š

1. å‘¨å¿—åã€Š**æœºå™¨å­¦ä¹ **ã€‹ï¼šè¿™æœ¬ä¹¦æ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸçš„ç»å…¸å…¥é—¨æ•™æä¹‹ä¸€ï¼Œè¢«ç§°ä¸ºâ€œè¥¿ç“œä¹¦â€ã€‚å®ƒæ¶µç›–äº†æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†å’Œå„ç§ç®—æ³•ï¼Œå†…å®¹å…¨é¢ä¸”æ˜“äºç†è§£ï¼Œé€‚åˆåˆå­¦è€…å…¥é—¨ã€‚ **Github** **èµ„æº**ï¼š https://github.com/datawhalechina/pumpkin-book _å¼€æºç»„ç»‡Datawhaleå°†ã€Šæœºå™¨å­¦ä¹ ã€‹ä¸­1-16ç« èŠ‚çš„å…¬å¼è¿›è¡Œäº†æ•´ç†ï¼Œå¹¶å¯¹éš¾ç‚¹å…¬å¼è¿›è¡Œäº†è¯¦è§£å’Œè¡¥å……ï¼Œåˆ›å»ºäº†ã€Špumpkin-bookã€‹å—ç“œä¹¦é¡¹ç›®_ https://github.com/Vay-keen/Machine-learning-learning-notes _å‘¨å¿—åã€Šæœºå™¨å­¦ä¹ ã€‹çš„å­¦ä¹ ç¬”è®°ï¼Œè®°å½•äº†åœ¨å­¦ä¹ è¿™æœ¬ä¹¦çš„è¿‡ç¨‹ä¸­çš„ç†è§£æ€è·¯ä»¥åŠä¸€äº›æœ‰åŠ©äºæ¶ˆåŒ–ä¹¦å†…å®¹çš„æ‹“å±•çŸ¥è¯†ï¼Œç¬”è®°ä¸­å‚è€ƒäº†è®¸å¤šç½‘ä¸Šçš„å¤§ç‰›ç»å…¸åšå®¢ä»¥åŠæèˆªã€Šç»Ÿè®¡å­¦ä¹ ã€‹çš„å†…å®¹ã€‚_
    

- æèˆª ã€Š**ç»Ÿè®¡å­¦ä¹ æ–¹æ³•**ã€‹è¿™æœ¬ä¹¦å…¨é¢ç³»ç»Ÿåœ°ä»‹ç»äº†ç»Ÿè®¡å­¦ä¹ çš„ä¸»è¦æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼ŒåŒ…æ‹¬æ„ŸçŸ¥æœºã€kè¿‘é‚»æ³•ã€æœ´ç´ è´å¶æ–¯æ³•ã€å†³ç­–æ ‘ã€é€»è¾‘æ–¯è°›å›å½’ä¸æ”¯æŒå‘é‡æœºã€æå‡æ–¹æ³•ã€EMç®—æ³•ã€éšé©¬å°”å¯å¤«æ¨¡å‹å’Œæ¡ä»¶éšæœºåœºç­‰ã€‚ **Github** **èµ„æº**ï¼šhttps://github.com/zhengjingwei/statistical-learning-method _ç”¨pythonæ‰‹åŠ¨å®ç°å’Œ__sklearn__å®ç°ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ä¸­æ‰€æåˆ°çš„ç®—æ³•ã€‚_https://github.com/datawhalechina/statistical-learning-method-solutions-manual å®Œæˆäº†ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹çš„æ‰€æœ‰ä¹ é¢˜è§£ç­”ï¼Œå¹¶æä¾›Pythonä»£ç å’Œè¿è¡Œæˆªå›¾ã€‚å†…å®¹åŒ…æ‹¬æ„ŸçŸ¥æœºã€Kè¿‘é‚»æ³•ã€æœ´ç´ è´å¶æ–¯æ³•ã€å†³ç­–æ ‘ã€é€»è¾‘æ–¯è’‚å›å½’ä¸æœ€å¤§ç†µæ¨¡å‹ã€æ”¯æŒå‘é‡æœºã€æå‡æ–¹æ³•ã€EMç®—æ³•ã€éšé©¬å°”å¯å¤«æ¨¡å‹ã€æ¡ä»¶éšæœºåœºç­‰ç« èŠ‚çš„ä¹ é¢˜è§£ç­”ã€‚ https://github.com/WenDesi/lihang_book_algorithm è‡´åŠ›äºå°†ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ä¸€ä¹¦ä¸­æ‰€æœ‰ç®—æ³•å®ç°ä¸€éã€‚æä¾›äº†è¯¦ç»†çš„ä»£ç ç¤ºä¾‹å’Œæ³¨é‡Šï¼Œå¸®åŠ©è¯»è€…ç†è§£å’Œå®ç°ä¹¦ä¸­çš„ç®—æ³•
    

1. å´æ©è¾¾çš„Coursera MLè¯¾ç¨‹ï¼šhttps://www.coursera.org/learn/machine-learning
    
2. Scikitå­¦ä¹ ç”¨æˆ·æŒ‡å—ï¼šhttps://scikit-learn.org/stable/user_guide.html
    

  

3. **ç»ƒä¹ æœºå™¨å­¦ä¹ æ¨¡å‹**

- ç»ƒä¹ ä½¿ç”¨Scikit-Learnæ„å»ºç®€å•æ¨¡å‹ã€‚
    
- ä½¿ç”¨Kaggleæˆ–UCIæœºå™¨å­¦ä¹ åº“ä¸­çš„æ•°æ®é›†æ¥å®ç°æ‚¨çš„æ¨¡å‹ã€‚
    

### **æ­¥éª¤2: ä¸­çº§****æœºå™¨å­¦ä¹ ****æŠ€æœ¯**

1. **æ·±åº¦å­¦ä¹ ****åŸºç¡€**
    

- äº†è§£ç¥ç»ç½‘ç»œã€æ¿€æ´»å‡½æ•°ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ã€‚
    
- äº†è§£åå‘ä¼ æ’­å’Œæ¢¯åº¦ä¸‹é™çš„åŸºç¡€çŸ¥è¯†ã€‚
    

**èµ„æº**ï¼š

1. Ian Goodfellow, Yoshua Bengio, and Aaron Courvilleã€ŠDeep Learningã€‹è¿™æœ¬ä¹¦æ˜¯æ·±åº¦å­¦ä¹ é¢†åŸŸçš„ç»å…¸è‘—ä½œï¼Œè¢«ç§°ä¸ºâ€œ**æ·±åº¦å­¦ä¹ ****AI****åœ£ç»**â€ã€‚å®ƒæ¶µç›–äº†æ·±åº¦å­¦ä¹ çš„æ¦‚å¿µã€æ–¹æ³•ä»¥åŠå·¥ä¸šç•Œå®è·µåº”ç”¨ï¼Œé€‚åˆå¯¹æ·±åº¦å­¦ä¹ æ„Ÿå…´è¶£çš„è¯»è€…æ·±å…¥å­¦ä¹ ã€‚
    
2. Christopher Bishopã€ŠPattern Recognition and Machine Learningã€‹æ¯”è¾ƒè€ï¼Œä½†æ˜¯éå¸¸ç»å…¸çš„è¯»ç‰©ï¼Œç›¸å¯¹ã€ŠDeep Learningã€‹å®¹æ˜“ç†è§£ä¸€äº›ã€‚
    
3. æ·±åº¦å­¦ä¹  Coursera è¯¾ç¨‹ï¼šhttps://www.coursera.org/specializations/deep-learning
    
4. TensorFlow.orgæ•™ç¨‹ï¼šhttps://www.tensorflow.org/tutorials
    

5. **æ·±åº¦å­¦ä¹ ****æ¡†æ¶**

- è·å¾—TensorFlowå’ŒPyTorchçš„å®è·µç»éªŒã€‚
    
- ä»æ„å»ºç”¨äºåˆ†ç±»å’Œå›å½’ä»»åŠ¡çš„ç®€å•ç¥ç»ç½‘ç»œå¼€å§‹ã€‚
    

3. **è¯„ä¼°æŒ‡æ ‡å’Œæ¨¡å‹è°ƒæ•´**

- äº†è§£è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚å‡†ç¡®æ€§ã€ç²¾ç¡®åº¦ã€å¬å›ç‡ã€F1è¯„åˆ†ã€ROCæ›²çº¿å’ŒAUCã€‚
    
- ç»ƒä¹ è¶…å‚æ•°è°ƒæ•´ã€æ­£åˆ™åŒ–å’Œæ¨¡å‹é€‰æ‹©ã€‚
    

### **æ­¥éª¤3:** **NLP****å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆ****LLMs****ï¼‰**

1. **è‡ªç„¶è¯­è¨€å¤„ç†****ï¼ˆ****NLP****ï¼‰åŸºç¡€**
    

- äº†è§£Tokenizationã€Embeddingã€Indexingç­‰æŠ€æœ¯ã€‚
    
- ç†è§£RAGæŠ€æœ¯ï¼Œäº†è§£å¦‚ä½•ä»Huggingfaceè°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚
    

**èµ„æº**ï¼š

1. HuggingFaceä¸Šçš„èµ„æº https://huggingface.co/learn/nlp-course/
    
2. Jurafskyå’ŒMartinçš„ã€ŠSpeech and Language Processingã€‹https://web.stanford.edu/~jurafsky/slp3/ ç¬¬ä¸‰ç‰ˆçš„ç”µå­èµ„æº
    
3. Delip Raoå’ŒBrian McMahançš„ â€œNatural Language Processing with PyTorchâ€
    
4. æ–¯å¦ç¦NLPè¯¾ç¨‹ï¼šhttps://web.stanford.edu/class/cs224n/
    

  

5. **Transformerså’Œ****LLM**

- äº†è§£æ„æˆLLMåŸºç¡€çš„Transformeræ¶æ„ã€‚
    
- ç ”ç©¶æ³¨æ„åŠ›æœºåˆ¶ã€åºåˆ—åˆ°åºåˆ—æ¨¡å‹å’Œè‡ªæˆ‘æ³¨æ„åŠ›ã€‚
    

**èµ„æº**ï¼š

1. ã€ŠTransformerã€‹ï¼šhttps://jalammar.github.io/illustrated-transformer/
    
2. â€œAttention is All You Needâ€è®ºæ–‡ï¼šhttps://arxiv.org/abs/1706.03762
    
3. HuggingFace Transformersæ¦‚è¿°ï¼šhttps://huggingface.co/transformers/
    

  

4. **LLMå®è·µ**

- å­¦ä¹ ä½¿ç”¨é¢„è®­ç»ƒçš„LLMï¼Œå¦‚GPTã€BERTï¼Œå¹¶é’ˆå¯¹ç‰¹å®šä»»åŠ¡å¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚
    
- **æ¡†æ¶**ï¼šHuggingFace Transformersï¼Œç”¨äºå®ç°æœ€å…ˆè¿›çš„NLPæ¨¡å‹ã€‚
    
- ä½¿ç”¨HuggingFaceç»ƒä¹ æ–‡æœ¬åˆ†ç±»ã€æ‘˜è¦å’Œç”Ÿæˆã€‚
    

### **æ­¥éª¤4: åº”ç”¨å’Œå®è·µ**

1. **æ„å»ºæœºå™¨å­¦ä¹ é¡¹ç›®**

- å®æ–½å„ç§æœºå™¨å­¦ä¹ é¡¹ç›®ï¼Œå¦‚è‚¡ä»·é¢„æµ‹ã€æƒ…ç»ªåˆ†æå’Œæ¨èç³»ç»Ÿã€‚
    
- å°†è®¡é‡ç»æµå­¦çŸ¥è¯†åº”ç”¨äºæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä»¥è§£å†³é‡‘èç›¸å…³é—®é¢˜ã€‚
    

2. **å¾®è°ƒLLMs**

- æ‰¿æ‹…æ¶‰åŠèŠå¤©æœºå™¨äººã€æ‘˜è¦å·¥å…·æˆ–ä½¿ç”¨LLMè¿›è¡Œè¯­è¨€ç¿»è¯‘çš„é¡¹ç›®ã€‚
    
- ç»ƒä¹ ä½¿ç”¨ä¸åŒçš„æ•°æ®é›†ï¼Œå¦‚è´¢åŠ¡æŠ¥å‘Šã€ç¤¾äº¤åª’ä½“æ•°æ®æˆ–å…¶ä»–ç‰¹å®šé¢†åŸŸçš„æ–‡æœ¬ï¼Œä¸ºè‡ªå®šä¹‰åº”ç”¨ç¨‹åºå¾®è°ƒLLMã€‚
    

3. **å¼ºåŒ–å­¦ä¹ **

- å­¦ä¹ å¼ºåŒ–å­¦ä¹ ï¼ˆå¦‚Bandit learning, Q-learningï¼‰å’Œå¯¹æŠ—æ¨¡å‹ï¼ˆGANï¼‰çš„åŸºç¡€çŸ¥è¯†ã€‚
    
- æ¢ç´¢è¿™äº›åœ¨é‡‘èä¸­çš„åº”ç”¨ï¼Œå¦‚ç®—æ³•äº¤æ˜“ã€‚
    

4. **ç ”ç©¶è®ºæ–‡å’Œå®è·µç»éªŒ**

- å¼€å§‹é˜…è¯»ç›¸å…³çš„ç ”ç©¶è®ºæ–‡ï¼Œäº†è§£æœ€æ–°è¿›å±•ã€‚
    
- å®æ–½å’Œå®éªŒè®ºæ–‡ä¸­çš„æ¨¡å‹ï¼Œä»¥äº²èº«äº†è§£å‰æ²¿ç ”ç©¶ã€‚
    

## å°ç™½0åŸºç¡€ï¼Œè½¬è¡Œå¤§æ¨¡å‹

- å…¥é—¨ç¯‡ï¼š
    
    - äº†è§£å¤§è¯­è¨€æ¨¡å‹çš„åŸºç¡€çŸ¥è¯†å’Œå¸¸è§æœ¯è¯­ã€‚
        
    - å­¦ä¼šä½¿ç”¨ç¼–ç¨‹è¯­è¨€è®¿é—® OpenAI API ç­‰å¸¸è§å¤§è¯­è¨€æ¨¡å‹æ¥å£ã€‚
        
    - é¢å‘éä¸“ä¸šèƒŒæ™¯çš„å¤§æ¨¡å‹æ™®åŠçŸ¥è¯†ã€‚
        
- åº”ç”¨ç¯‡ï¼š
    
    - å¯ä»¥åœ¨æœ¬åœ°ç¯å¢ƒæ­å»ºå¼€æºæ¨¡å‹çš„æ¨ç†ç¯å¢ƒã€‚
        
    - å¤§è¯­è¨€æ¨¡å‹åº”ç”¨å¼€å‘æ¡†æ¶ï¼ˆå¦‚ LangChainã€Difyç­‰ï¼‰ã€‚
        
    - Prompt å·¥ç¨‹ã€ RAGã€Agent ç­‰å¤§æ¨¡å‹åº”ç”¨å¼€å‘èŒƒå¼ã€‚
        
- æ·±å…¥ç¯‡ï¼š
    
    - å¤§æ¨¡å‹æŠ€æœ¯åŸç†ã€è®­ç»ƒå¾®è°ƒã€æ•°æ®å·¥ç¨‹ã€æ¨ç†ä¼˜åŒ–ç­‰ã€‚
        
    - å¤§æ¨¡å‹åº”ç”¨èŒƒå¼ï¼ˆRAGã€Agentç­‰ï¼‰å‰æ²¿è¿›å±•ã€‚
        
    
    ### Â Â **0x10 å…¥é—¨ç¯‡**
    

> åœ¨å…¥é—¨ä¹‹å‰ï¼Œè¯·ç”³è¯· OpenAI APIï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„å›½é™…äº’è”ç½‘è®¿é—®æ¡ä»¶ã€‚ æ¨èæ³¨å†Œ [https://openrouter.ai/](https://openrouter.ai/) å¯ä¸€ç«™å¼è®¿é—®å¤§é‡é—­æºå’Œå¼€æºæ¨¡å‹ã€‚

- [ChatGPT Prompt Engineering for Developers](https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction)
    
    - è™½ç„¶æ˜¯ Prompt å·¥ç¨‹ï¼Œä½†æ˜¯å†…å®¹æ¯”è¾ƒç®€å•ï¼Œé€‚åˆå…¥é—¨è€…ã€‚
        
    - ä¸­è‹±åŒè¯­å­—å¹•ï¼š [https://github.com/GitHubDaily/ChatGPT-Prompt-Engineering-for-Developers-in-Chinese](https://github.com/GitHubDaily/ChatGPT-Prompt-Engineering-for-Developers-in-Chinese)
        
- [OpenAI Quickstart](https://platform.openai.com/docs/quickstart) ã€å¿…çœ‹ã€‘
    
    - OpenAI å®˜æ–¹ Quickstart æ–‡æ¡£ã€‚ä»¥åŠ [API Reference](https://platform.openai.com/docs/api-reference)
        
- State of GPTï¼šAndrej Karpathy åšçš„æ¼”ç¤ºï¼Œæå¥½çš„æ€»ç»“äº† GPT çš„è®­ç»ƒå’Œåº”ç”¨ã€‚ ã€å¿…çœ‹ã€‘
    
    - è§†é¢‘ï¼š [https://www.youtube.com/watch?v=bZQun8Y4L2A](https://www.youtube.com/watch?v=bZQun8Y4L2A)
        
    - PPTï¼š [https://karpathy.ai/stateofgpt.pdf](https://karpathy.ai/stateofgpt.pdf)
        
- Deep Dive into LLMs like ChatGPT: Andrej Karpathy æœ€æ–°çš„é•¿è¾¾3å°æ—¶çš„å…¥é—¨è§†é¢‘ã€å¿…çœ‹ã€‘ è§†é¢‘ï¼š[https://www.youtube.com/watch?v=7xTGNNLPyMI](https://www.youtube.com/watch?v=7xTGNNLPyMI) ä¸­è‹±åŒè¯­å­—å¹•ï¼š[https://b23.tv/vF2vS6t](https://b23.tv/vF2vS6t)
    

### **0x20 åº”ç”¨ç¯‡**

- [Building Systems with the ChatGPT API](https://learn.deeplearning.ai/chatgpt-building-system/lesson/1/introduction)
    
    - ä¸­æ–‡å­—å¹•ï¼š [https://www.bilibili.com/video/BV1gj411X72B/](https://www.bilibili.com/video/BV1gj411X72B/)
        
- [Langchain](https://python.langchain.com/)
    
    - Langchain æ˜¯å¤§è¯­è¨€æ¨¡å‹æœ€ç«çš„åº”ç”¨æ¡†æ¶ã€‚å³ä½¿ä¸ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥å€Ÿé‰´ã€‚
        
    - [LangChain for LLM Application Development](https://learn.deeplearning.ai/langchain/lesson/1/introduction)
        
        - ä¸­æ–‡å­—å¹•ï¼š [https://www.bilibili.com/video/BV1Ku411x78m/](https://www.bilibili.com/video/BV1Ku411x78m/)
            
- [dify](https://dify.ai/)ï¼šå¼€æºçš„åº”ç”¨ç¼–æ’å·¥å…·ã€‚
    
- [GPT best practices](https://platform.openai.com/docs/guides/gpt-best-practices/gpt-best-practices)ï¼šOpenAI å®˜æ–¹å‡ºçš„æœ€ä½³å®è·µã€‚
    
- [openai-cookbook](https://github.com/openai/openai-cookbook)ï¼šOpenAI å®˜æ–¹ Cookbookã€‚
    
- [Brex's Prompt Engineering Guide](https://github.com/brexhq/prompt-engineering)ï¼šPrompt å·¥ç¨‹ç®€ä»‹
    

### **0x30 æ·±å…¥ç¯‡**

#### **0x31 å¤§æ¨¡å‹æŠ€æœ¯åŸºç¡€æ–¹å‘**

- [ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹](https://zh.d2l.ai/)ï¼šé…åˆ[Bç«™ææ²çš„è§†é¢‘](https://courses.d2l.ai/zh-v2/)ï¼Œæ˜¯æˆ‘ä¸ªäººè®¤ä¸ºæœ€å¥½çš„æ·±åº¦å­¦ä¹ å…¥é—¨è¯¾ç¨‹ã€‚ã€å¿…çœ‹ã€‘
    
- [æ·±åº¦å­¦ä¹ ï¼šå°æ¹¾å¤§å­¦æå®æ¯…](https://www.bilibili.com/video/BV1J94y1f7u5/)ï¼šå°æ¹¾å¤§å­¦æå®æ¯…ï¼Œè®²çš„å¾ˆæ¸…æ¥šï¼Œä¹Ÿæ¯”è¾ƒæœ‰è¶£ã€‚
    
- [3brown1blue ç³»åˆ—è§†é¢‘](https://www.youtube.com/watch?v=wjZofJX0v4M)ï¼šåŠ¨ç”»åšçš„å¾ˆå¥½ï¼Œå¯åå¤å›é¡¾ ã€å¿…çœ‹ã€‘
    

#### **0x32 å¤§æ¨¡å‹æŠ€æœ¯åŸç†æ–¹å‘**

- [å¤§è¯­è¨€æ¨¡å‹ç»¼è¿°](https://github.com/RUCAIBox/LLMSurvey)ã€å¿…çœ‹ã€‘
    
    - å¤§è¯­è¨€æ¨¡å‹è¿„ä»Šä¸ºæ­¢æœ€å¥½çš„å­¦æœ¯å‘ä¸­æ–‡ç»¼è¿°ã€‚
        
- [å¤§è¯­è¨€æ¨¡å‹](https://github.com/LLMBook-zh/LLMBook-zh.github.io)ã€å¿…çœ‹ã€‘
    
    - å¤§è¯­è¨€æ¨¡å‹è¿„ä»Šä¸ºæ­¢æœ€å¥½çš„ä¹¦ç±ã€‚
        
- [å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼šä»ç†è®ºåˆ°å®è·µ](https://intro-llm.github.io/)ï¼šå¦ä¸€æœ¬ä¸é”™çš„ä¸­æ–‡ä¹¦ç±ã€‚
    
- [æ¸…åå¤§æ¨¡å‹å…¬å¼€è¯¾ç¬¬äºŒå­£](https://www.bilibili.com/video/BV1pf421z757)ï¼šç³»ç»Ÿçš„äº†è§£å¤§æ¨¡å‹çš„å†å²ã€åŸç†å’Œå‰æ²¿è¿›å±•ã€‚ã€å¿…çœ‹ã€‘
    
- [GPTï¼ŒGPT-2ï¼ŒGPT-3 è®ºæ–‡ç²¾è¯»](https://www.bilibili.com/video/BV1AF411b7xQ)ï¼šGPT ç³»åˆ—æ¨¡å‹è®ºæ–‡ç²¾è¯»
    
- [Llama3.1 è®ºæ–‡ç²¾è¯»](https://www.bilibili.com/video/BV1WM4m1y7Uh)ï¼šæœ€å¥½çš„å¼€æºå¤§æ¨¡å‹è®ºæ–‡ç²¾è¯»
    
- [å¤æ‚æ¨ç†ï¼šå¤§è¯­è¨€æ¨¡å‹çš„åŒ—ææ˜Ÿèƒ½åŠ›](https://yaofu.notion.site/6dafe3f8d11445ca9dcf8a2ca1c5b199) ï¼šç•¥å­¦æœ¯ï¼Œè§£é‡Šå¤§è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„æ¥æºã€‚
    
- [ICML 2024 Tutorial: Physics of Language Models by Zeyuan Allen-Zhu](https://www.bilibili.com/video/BV1TPpbeVEUi/)ï¼šä½¿ç”¨é»‘ç›’ç ”ç©¶å¤§æ¨¡å‹çš„åŸç†ï¼Œéå¸¸æœ‰å‚è€ƒä»·å€¼ã€‚ã€å¿…çœ‹ã€‘
    

#### **0x33 å¤§æ¨¡å‹è®­ç»ƒå¾®è°ƒæ–¹å‘**

- [Build a Large Language Model (From Scratch)](https://github.com/rasbt/LLMs-from-scratch)ï¼šä»é›¶æ„å»ºå¤§æ¨¡å‹ã€‚ã€å¿…çœ‹ã€‘
    
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)ï¼šä¸ªäººæœ€æ¨èçš„å¾®è°ƒå¤§æ¨¡å‹çš„å·¥å…·ã€‚ã€å¿…çœ‹ã€‘
    
- [MAP-NEO](https://github.com/multimodal-art-projection/MAP-NEO)ï¼šå”¯ä¸€å…¨è¿‡ç¨‹å¼€æºçš„ä¸­æ–‡å¤§æ¨¡å‹ï¼ˆåŒ…æ‹¬æ•°æ®å¤„ç†å·¥å…·ã€é¢„è®­ç»ƒæ•°æ®ã€å¾®è°ƒæ•°æ®ç­‰ï¼‰
    

#### **0x34 å¤§æ¨¡å‹æ•°æ®å·¥ç¨‹æ–¹å‘**

- [How to Generate and Use Synthetic Data for Finetuning](https://eugeneyan.com/writing/synthetic/)ï¼šå¦‚ä½•åˆæˆå¾®è°ƒæ•°æ®ã€‚
    
- [ä¸­æ–‡è¡Œä¸šé¢„è®­ç»ƒè¯­æ–™ IndustryCorpus 2.0](https://data.baai.ac.cn/details/BAAI-IndustryCorpus-v2)ï¼šäº®ç‚¹æ˜¯é¢„è®­ç»ƒæ•°æ®å¤„ç†æµæ¯”è¾ƒç§‘å­¦ã€‚[æ•°æ®å¤„ç†å·¥å…· FlagData](https://github.com/FlagOpen/FlagData/blob/main/README_zh.md)
    

#### **0x35 å¤§æ¨¡å‹æ¨ç†ä¼˜åŒ–æ–¹å‘**

- [Challenges in Deploying Long-Context Transformers: A Theoretical Peak Performance Analysis](https://arxiv.org/abs/2405.08944)ï¼šå¤§æ¨¡å‹æ¨ç†é€Ÿåº¦è®¡ç®—å’Œç“¶é¢ˆåˆ†æã€‚ã€å¿…çœ‹ã€‘
    
- [A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)ï¼šå¤§æ¨¡å‹é‡åŒ–è§£æã€‚
    

#### **0x36 å¤§æ¨¡å‹åº”ç”¨æ–¹å‘**

- [A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks](https://arxiv.org/abs/2407.12994): Prompt å·¥ç¨‹ç»¼è¿°
    
- [Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks](https://arxiv.org/pdf/2407.21059)ï¼šé«˜çº§ RAG ä¼˜åŒ–æ–¹æ³•ã€‚
    
- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)ï¼šAgent æ—©æœŸçš„å¾ˆä¸é”™çš„æ–‡ç« ã€‚
    

### **æ¨èå·¥å…·**

- **VS Code**æˆ–**Jupyter Notebook**ç”¨äºå®éªŒã€‚
    
- **Huggingface**é€‚åˆLLMsã€‚
    
- **Scikit learn**ï¼Œ**TensorFlow**ï¼Œ**PyTorch**ç”¨äºMLã€‚
    

  

  

æ¨èå¼€æºé¡¹ç›®ï¼š

1. ## https://github.com/hesamsheikh/ml-retreat
    

![](https://ccn7vpu5l5y8.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjJhNWEwN2E4NGFlNTA0YTk4YmE3NmYwMjZhNWU0OWZfN2JTS1ZaYVlEd3cxSHV3WHRpdTBVTWFoTDdNaXMzVHBfVG9rZW46QnVMVGJqN1pHb2E4cFJ4TWU2dmNoc1FWbnBlXzE3NjIzNDY5NDI6MTc2MjM1MDU0Ml9WNA)

2. ## https://roadmap.sh/ai-engineer
    

![](https://ccn7vpu5l5y8.feishu.cn/space/api/box/stream/download/asynccode/?code=MjY1Y2E3ZDkyNzViZTMyNzk3ODNlY2Q5NTc5YWM5NTVfNTFjeHV3UDV6Qm82dEdTT2hDaGt6Z1RsWU1EZkl5QjRfVG9rZW46UU9EdmJPanZIb1FvYWh4dUNFN2NMNzU1bm5oXzE3NjIzNDY5NDI6MTc2MjM1MDU0Ml9WNA)

  

  

3. ## https://github.com/datawhalechina/so-large-lm
    

![](https://ccn7vpu5l5y8.feishu.cn/space/api/box/stream/download/asynccode/?code=YmFjZjlhOTE4NzRmMzEyZWVlYTMzMDZjNmVjYzk2NjFfQWI3QWE1TlZjWTgzZ0haMjg1VklCSDdVVG4wVW5EN1FfVG9rZW46R3lXRmJkTUpIb0hFa3d4WjlIdWNmdHFDbjBiXzE3NjIzNDY5NDI6MTc2MjM1MDU0Ml9WNA)

  

4. ## https://github.com/kebijuelun/Awesome-LLM-Learning
    

![](https://ccn7vpu5l5y8.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjA5Yzk3MWM3MTAwMDE3Y2I0NzljNmU0NTJhZTNhMTFfMVV2MEtKYzhQMDluR2l2dnlmU0JTSG85ZkRvaHg4dVRfVG9rZW46Tnk1cmJQZ2d4bzFSSFV4SGl0M2NyQUZHbnlmXzE3NjIzNDY5NDI6MTc2MjM1MDU0Ml9WNA)

  

5. ## https://github.com/liguodongiot/llm-action
    

![](https://ccn7vpu5l5y8.feishu.cn/space/api/box/stream/download/asynccode/?code=ZTMyMzRlNTRmYWNmOWY5ZDFhYjA1ZDFmYjQ2NzU5MzdfdGVhMnl2N3hHTm5MRWVWV0ZteDRHY3ozd0ZjZE5IVnhfVG9rZW46U3Q1M2JYR1V0b1N0TW54ZFBQb2NlUzZabmRlXzE3NjIzNDY5NDI6MTc2MjM1MDU0Ml9WNA)

  

6. ## [Datawhaleå¤§æ¨¡å‹è¯¾ç¨‹é£Ÿç”¨æŒ‡å—](https://datawhaler.feishu.cn/wiki/Pbruw4cZEiFLmrkXNmGcFhB2nId)ï¼ˆæ¨èï¼‰
    

æš‚æ—¶æ— æ³•åœ¨é£ä¹¦æ–‡æ¡£å¤–å±•ç¤ºæ­¤å†…å®¹

  

7. ## https://github.com/Lordog/dive-into-llms
    

![](https://ccn7vpu5l5y8.feishu.cn/space/api/box/stream/download/asynccode/?code=NTYxOTJhYzJlMWZkNWViOTlhMjFiNzUzZjg1MjE3ODJfZnBzRHZ5ZGFkQ3p5TU00cjBkSDJuMGlydjZNVDlFc2tfVG9rZW46V3ppRWJVV25Db1pjSTR4ZG1FdmMzamFhbnFnXzE3NjIzNDY5NDI6MTc2MjM1MDU0Ml9WNA)

  

h


### 1. æœºå™¨å­¦ä¹ çš„æ•°å­¦

  

åœ¨æŒæ¡æœºå™¨å­¦ä¹ ä¹‹å‰ï¼Œäº†è§£é©±åŠ¨è¿™äº›ç®—æ³•çš„åŸºæœ¬æ•°å­¦æ¦‚å¿µéå¸¸é‡è¦ã€‚

  

- **çº¿æ€§ä»£æ•°**ï¼šè¿™å¯¹äºç†è§£è®¸å¤šç®—æ³•å°¤å…¶æ˜¯åœ¨æ·±åº¦å­¦ä¹ ä¸­ä½¿ç”¨çš„ç®—æ³•è‡³å…³é‡è¦ã€‚å…³é”®æ¦‚å¿µåŒ…æ‹¬å‘é‡ã€çŸ©é˜µã€è¡Œåˆ—å¼ã€ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ã€å‘é‡ç©ºé—´å’Œçº¿æ€§å˜æ¢ã€‚
    
- **å¾®ç§¯åˆ†**ï¼šè®¸å¤šæœºå™¨å­¦ä¹ ç®—æ³•æ¶‰åŠè¿ç»­å‡½æ•°çš„ä¼˜åŒ–ï¼Œè¿™éœ€è¦ç†è§£å¯¼æ•°ã€ç§¯åˆ†ã€æé™å’Œçº§æ•°ã€‚å¤šå˜é‡å¾®ç§¯åˆ†å’Œæ¢¯åº¦æ¦‚å¿µä¹Ÿå¾ˆé‡è¦ã€‚
    
- **æ¦‚ç‡ä¸ç»Ÿè®¡**ï¼šè¿™äº›å¯¹äºç†è§£æ¨¡å‹å¦‚ä½•ä»æ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºé¢„æµ‹è‡³å…³é‡è¦ã€‚å…³é”®æ¦‚å¿µåŒ…æ‹¬æ¦‚ç‡è®ºã€éšæœºå˜é‡ã€æ¦‚ç‡åˆ†å¸ƒã€æœŸæœ›ã€æ–¹å·®ã€åæ–¹å·®ã€ç›¸å…³æ€§ã€å‡è®¾æ£€éªŒã€ç½®ä¿¡åŒºé—´ã€æœ€å¤§ä¼¼ç„¶ä¼°è®¡å’Œè´å¶æ–¯æ¨æ–­ã€‚
    

  

ğŸ“š èµ„æºï¼š

  

- [3Blue1Brown - çº¿æ€§ä»£æ•°çš„ç²¾é«“](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)ï¼šä¸€ç³»åˆ—è§†é¢‘ï¼Œæä¾›äº†è¿™äº›æ¦‚å¿µçš„å‡ ä½•ç›´è§‚æ„Ÿå—ã€‚
    
- [StatQuest with Josh Starmer - ç»Ÿè®¡å­¦åŸºç¡€](https://www.youtube.com/watch?v=qBigTkBLU6g&list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9)ï¼šä¸ºè®¸å¤šç»Ÿè®¡æ¦‚å¿µæä¾›ç®€å•æ˜äº†çš„è§£é‡Šã€‚
    
- [AP Statistics Intuition by Ms Aerin](https://automata88.medium.com/list/cacc224d5e7d)ï¼šMediumæ–‡ç« åˆ—è¡¨ï¼Œæä¾›äº†æ¯ä¸ªæ¦‚ç‡åˆ†å¸ƒèƒŒåçš„ç›´è§‰ç†è§£ã€‚
    
- [æ²‰æµ¸å¼çº¿æ€§ä»£æ•°](https://immersivemath.com/ila/learnmore.html)ï¼šçº¿æ€§ä»£æ•°çš„å¦ä¸€ç§è§†è§‰è§£è¯»ã€‚
    
- [Khan Academy - çº¿æ€§ä»£æ•°](https://www.khanacademy.org/math/linear-algebra)ï¼šéå¸¸é€‚åˆåˆå­¦è€…ï¼Œä»¥éå¸¸ç›´è§‚çš„æ–¹å¼è§£é‡Šæ¦‚å¿µã€‚
    
- [Khan Academy - å¾®ç§¯åˆ†](https://www.khanacademy.org/math/calculus-1)ï¼šä¸€ä¸ªæ¶µç›–æ‰€æœ‰åŸºç¡€å¾®ç§¯åˆ†æ¦‚å¿µçš„äº’åŠ¨è¯¾ç¨‹ã€‚
    
- [Khan Academy - æ¦‚ç‡ä¸ç»Ÿè®¡](https://www.khanacademy.org/math/statistics-probability)ï¼šä»¥æ˜“äºç†è§£çš„æ ¼å¼æä¾›ææ–™ã€‚
    

  

---

  

### 2. æœºå™¨å­¦ä¹ çš„Python

  

Pythonæ˜¯ä¸€ç§åŠŸèƒ½å¼ºå¤§ä¸”çµæ´»çš„ç¼–ç¨‹è¯­è¨€ï¼Œç‰¹åˆ«é€‚ç”¨äºæœºå™¨å­¦ä¹ ï¼Œè¿™å¾—ç›Šäºå…¶å¯è¯»æ€§ã€ä¸€è‡´æ€§å’Œå¥å£®çš„æ•°æ®ç§‘å­¦åº“ç”Ÿæ€ç³»ç»Ÿã€‚

  

- **PythonåŸºç¡€**ï¼šPythonç¼–ç¨‹éœ€è¦ç†è§£åŸºæœ¬è¯­æ³•ã€æ•°æ®ç±»å‹ã€é”™è¯¯å¤„ç†å’Œé¢å‘å¯¹è±¡ç¼–ç¨‹ã€‚
    
- **æ•°æ®ç§‘å­¦****åº“**ï¼šç†Ÿæ‚‰NumPyè¿›è¡Œæ•°å€¼æ“ä½œï¼Œç”¨Pandasè¿›è¡Œæ•°æ®å¤„ç†å’Œåˆ†æï¼Œç”¨Matplotlibå’ŒSeabornåšæ•°æ®å¯è§†åŒ–ã€‚
    
- **æ•°æ®é¢„å¤„ç†**ï¼šæ¶‰åŠç‰¹å¾ç¼©æ”¾å’Œè§„èŒƒåŒ–ã€å¤„ç†ç¼ºå¤±æ•°æ®ã€å¼‚å¸¸æ£€æµ‹ã€ç±»åˆ«æ•°æ®ç¼–ç ï¼Œä»¥åŠå°†æ•°æ®åˆ†å‰²ä¸ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†ã€‚
    
- **æœºå™¨å­¦ä¹ ****åº“**ï¼šç†Ÿç»ƒä½¿ç”¨Scikit-learnï¼Œè¿™æ˜¯ä¸€ä¸ªæä¾›å¹¿æ³›çš„ç›‘ç£å’Œæ— ç›‘ç£å­¦ä¹ ç®—æ³•çš„pythonåº“ï¼Œè‡³å…³é‡è¦ã€‚ç†è§£å¦‚ä½•å®ç°çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æœ€è¿‘é‚»ï¼ˆK-NNï¼‰å’ŒKå‡å€¼èšç±»ç­‰ç®—æ³•å¾ˆé‡è¦ã€‚é™ç»´æŠ€æœ¯å¦‚PCAå’Œt-SNEå¯¹äºå¯è§†åŒ–é«˜ç»´æ•°æ®ä¹Ÿå¾ˆæœ‰å¸®åŠ©ã€‚
    

  

ğŸ“š èµ„æºï¼š

  

- [Real Python](https://realpython.com/)ï¼šä¸€ä¸ªå…¨é¢çš„èµ„æºï¼Œæä¾›é’ˆå¯¹Pythonåˆå­¦è€…å’Œé«˜çº§æ¦‚å¿µçš„æ–‡ç« å’Œæ•™ç¨‹ã€‚
    
- [freeCodeCamp - å­¦ä¹ Python](https://www.youtube.com/watch?v=rfscVS0vtbw)ï¼šæä¾›Pythonæ‰€æœ‰æ ¸å¿ƒæ¦‚å¿µå…¨é¢ä»‹ç»çš„é•¿è§†é¢‘ã€‚
    
- [Pythonæ•°æ®ç§‘å­¦æ‰‹å†Œ](https://jakevdp.github.io/PythonDataScienceHandbook/)ï¼šä¸€ä¸ªå¾ˆå¥½çš„å­¦ä¹ pandasã€NumPyã€Matplotlibå’ŒSeabornçš„å…è´¹æ•°å­—ä¹¦ã€‚
    
- [freeCodeCamp - æœºå™¨å­¦ä¹ å…¥é—¨](https://youtu.be/i_LwzRVP7bg)ï¼šä¸ºåˆå­¦è€…æä¾›ä¸åŒæœºå™¨å­¦ä¹ ç®—æ³•çš„å®ç”¨ä»‹ç»ã€‚
    
- [Udacity - æœºå™¨å­¦ä¹ å…¥é—¨](https://www.udacity.com/course/intro-to-machine-learning--ud120)ï¼šä¸€ä¸ªå…è´¹è¯¾ç¨‹ï¼Œæ¶µç›–äº†PCAå’Œå…¶ä»–å‡ ä¸ªæœºå™¨å­¦ä¹ æ¦‚
    

  

  

### 3. ç¥ç»ç½‘ç»œ

  

ç¥ç»ç½‘ç»œæ˜¯è®¸å¤šæœºå™¨å­¦ä¹ æ¨¡å‹çš„åŸºç¡€éƒ¨åˆ†ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸã€‚ä¸ºäº†æœ‰æ•ˆåœ°åˆ©ç”¨å®ƒä»¬ï¼Œå¯¹å®ƒä»¬çš„è®¾è®¡å’Œæœºåˆ¶æœ‰ä¸€ä¸ªå…¨é¢çš„ç†è§£æ˜¯å¿…è¦çš„ã€‚

  

- **åŸºç¡€çŸ¥è¯†**ï¼šè¿™åŒ…æ‹¬äº†è§£ç¥ç»ç½‘ç»œçš„ç»“æ„ï¼Œå¦‚å±‚ã€æƒé‡ã€åå·®å’Œæ¿€æ´»å‡½æ•°ï¼ˆsigmoidã€tanhã€ReLUç­‰ï¼‰ã€‚
    
- **è®­ç»ƒå’Œä¼˜åŒ–**ï¼šç†Ÿæ‚‰åå‘ä¼ æ’­å’Œä¸åŒç±»å‹çš„æŸå¤±å‡½æ•°ï¼Œå¦‚å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰å’Œäº¤å‰ç†µã€‚ç†è§£å„ç§ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚æ¢¯åº¦ä¸‹é™ã€éšæœºæ¢¯åº¦ä¸‹é™ã€RMSpropå’ŒAdamã€‚
    
- **è¿‡æ‹Ÿåˆ**ï¼šç†è§£è¿‡æ‹Ÿåˆçš„æ¦‚å¿µï¼ˆæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ä½†åœ¨æœªè§æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ï¼‰å¹¶å­¦ä¹ å„ç§æ­£åˆ™åŒ–æŠ€æœ¯ï¼ˆdropoutã€L1/L2æ­£åˆ™åŒ–ã€æå‰åœæ­¢ã€æ•°æ®å¢å¼ºï¼‰æ¥é˜²æ­¢å®ƒã€‚
    
- **å®ç°****å¤šå±‚æ„ŸçŸ¥æœº****ï¼ˆ****MLP****ï¼‰**ï¼šä½¿ç”¨PyTorchæ„å»ºä¸€ä¸ªMLPï¼Œä¹Ÿç§°ä¸ºå…¨è¿æ¥ç½‘ç»œã€‚
    

  

ğŸ“š èµ„æºï¼š

  

- [3Blue1Brown - ç¥ç»ç½‘ç»œæ˜¯ä»€ä¹ˆï¼Ÿ](https://www.youtube.com/watch?v=aircAruvnKk)ï¼šè¿™ä¸ªè§†é¢‘ç›´è§‚åœ°è§£é‡Šäº†ç¥ç»ç½‘ç»œåŠå…¶å†…éƒ¨å·¥ä½œåŸç†ã€‚
    
- [freeCodeCamp - æ·±åº¦å­¦ä¹ é€Ÿæˆè¯¾](https://www.youtube.com/watch?v=VyWAvY2CF9c)ï¼šè¿™ä¸ªè§†é¢‘é«˜æ•ˆåœ°ä»‹ç»äº†æ·±åº¦å­¦ä¹ ä¸­æ‰€æœ‰æœ€é‡è¦çš„æ¦‚å¿µã€‚
    
- [Fast.ai - å®ç”¨æ·±åº¦å­¦ä¹ ](https://course.fast.ai/)ï¼šä¸ºæœ‰ç¼–ç¨‹ç»éªŒæƒ³å­¦ä¹ æ·±åº¦å­¦ä¹ çš„äººè®¾è®¡çš„å…è´¹è¯¾ç¨‹ã€‚
    
- [Patrick Loeber - PyTorchæ•™ç¨‹](https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4)ï¼šä¸€ç³»åˆ—è§†é¢‘ï¼Œè®©å®Œå…¨çš„åˆå­¦è€…å­¦ä¹ PyTorchã€‚
    

  

---

  

### 4. è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰

  

NLPæ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªè¿·äººåˆ†æ”¯ï¼Œå®ƒæ¡¥æ¥äº†äººç±»è¯­è¨€ä¸æœºå™¨ç†è§£ä¹‹é—´çš„å·®è·ã€‚ä»ç®€å•çš„æ–‡æœ¬å¤„ç†åˆ°ç†è§£è¯­è¨€ç»†å¾®å·®åˆ«ï¼ŒNLPåœ¨è®¸å¤šåº”ç”¨ä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ï¼Œå¦‚ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€èŠå¤©æœºå™¨äººç­‰ç­‰ã€‚

  

- **æ–‡æœ¬é¢„å¤„ç†**ï¼šå­¦ä¹ å„ç§æ–‡æœ¬é¢„å¤„ç†æ­¥éª¤ï¼Œå¦‚åˆ†è¯ï¼ˆå°†æ–‡æœ¬åˆ†å‰²æˆå•è¯æˆ–å¥å­ï¼‰ã€è¯å¹²æå–ï¼ˆå°†è¯æ±‡è¿˜åŸåˆ°å…¶æ ¹å½¢å¼ï¼‰ã€è¯å½¢è¿˜åŸï¼ˆç±»ä¼¼äºè¯å¹²æå–ä½†è€ƒè™‘ä¸Šä¸‹æ–‡ï¼‰ã€åœç”¨è¯ç§»é™¤ç­‰ã€‚
    
- **ç‰¹å¾æå–æŠ€æœ¯**ï¼šç†Ÿæ‚‰å°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºæœºå™¨å­¦ä¹ ç®—æ³•èƒ½ç†è§£çš„æ ¼å¼çš„æŠ€æœ¯ã€‚å…³é”®æ–¹æ³•åŒ…æ‹¬è¯è¢‹ï¼ˆBoWï¼‰ã€è¯é¢‘-é€†æ–‡æ¡£é¢‘ç‡ï¼ˆTF-IDFï¼‰å’Œn-gramã€‚
    
- **è¯åµŒå…¥**ï¼šè¯åµŒå…¥æ˜¯ä¸€ç§è¯è¡¨ç¤ºæ–¹å¼ï¼Œå…è®¸æ„ä¹‰ç›¸è¿‘çš„è¯æœ‰ç›¸ä¼¼çš„è¡¨ç¤ºã€‚å…³é”®æ–¹æ³•åŒ…æ‹¬Word2Vecã€GloVeå’ŒFastTextã€‚
    
- **å¾ªç¯ç¥ç»ç½‘ç»œ****ï¼ˆRNNsï¼‰**ï¼šç†è§£RNNçš„å·¥ä½œåŸç†ï¼ŒRNNæ˜¯ä¸€ç§è®¾è®¡ç”¨æ¥å¤„ç†åºåˆ—æ•°æ®çš„ç¥ç»ç½‘ç»œã€‚æ¢ç´¢LSTMå’ŒGRUï¼Œè¿™ä¸¤ç§RNNå˜ä½“èƒ½å¤Ÿå­¦ä¹ é•¿æœŸä¾èµ–ã€‚
    

  

ğŸ“š èµ„æºï¼š

  

- [RealPython - ä½¿ç”¨spaCyè¿›è¡ŒPythonè‡ªç„¶è¯­è¨€å¤„ç†](https://realpython.com/natural-language-processing-spacy-python/)ï¼šå…³äºPythonä¸­spaCyåº“è¿›è¡ŒNLPä»»åŠ¡çš„è¯¦å°½æŒ‡å—ã€‚
    
- [Kaggle - NLPæŒ‡å—](https://www.kaggle.com/learn-guide/natural-language-processing)ï¼šä¸€äº›ç¬”è®°æœ¬å’Œèµ„æºï¼Œç”¨äºPythonä¸­NLPçš„å®è·µè§£é‡Šã€‚
    
- [Jay Alammar - Word2Vecå›¾è§£](https://jalammar.github.io/illustrated-word2vec/)ï¼šç†è§£è‘—åçš„Word2Vecæ¶æ„çš„å¥½å‚è€ƒã€‚
    
- [Jake Tae - ä»é›¶å¼€å§‹çš„PyTorch RNN](https://jaketae.github.io/study/pytorch-rnn/)ï¼šåœ¨PyTorchä¸­å®è·µå’Œç®€å•å®ç°RNNã€LSTMå’ŒGRUæ¨¡å‹ã€‚
    
- [colahçš„åšå®¢ - ç†è§£LSTMç½‘ç»œ](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)ï¼šå…³äºLSTMç½‘ç»œçš„æ›´ç†è®ºåŒ–æ–‡ç« ã€‚
    

  

åˆ—ä¸€ä¸ªå°åˆé›†ï¼š

  

1. å¤§æ¨¡å‹è®­ç»ƒåˆé›†ï¼Œunsloth ä¹‹å‰æ‰€æœ‰å¾®è°ƒå¤´éƒ¨å¼€æºæ¨¡å‹çš„æ–‡ç« åšäº†ä¸ªåˆé›†ï¼Œä»å¦‚ä½•å¾®è°ƒï¼Œå¦‚ä½•ä¼˜åŒ–ï¼Œæ¯ä¸ªæ¨¡å‹çš„æœ€ä½³è¿è¡Œå‚æ•°ï¼Œå¯èƒ½é‡åˆ°çš„é—®é¢˜ï¼Œå…¨éƒ½å†™å¾—å¾ˆè¯¦ç»†ã€‚https://docs.unsloth.ai/basics/tutorials-how-to-fine-tune-and-run-llms
    
      
    
2. å¼€æºå®è·µè¿›å±•ã€‚unslothåˆ¶ä½œäº†ä¸€ä»½å…³äºå¤§æ¨¡å‹å¼ºåŒ–å­¦ä¹ çš„å®Œæ•´æŒ‡å—å†…å®¹åŒ…æ‹¬ï¼šå¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡åŠå…¶åœ¨æ„å»ºæ™ºèƒ½ AI ä»£ç†ä¸­çš„å…³é”®ä½œç”¨ï¼› o3ã€Claude 4 å’Œ R1 ä¸ºä½•ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼› GRPOã€RLHFã€DPOã€å¥–åŠ±å‡½æ•°ï¼›é€šè¿‡ Unsloth è®­ç»ƒæœ¬åœ° R1 æ¨¡å‹ï¼Œhttps://docs.unsloth.ai/basics/reinforcement-learning-guid
    
      
    
3. swift:https://swift.readthedocs.io/zh-cn/latest/Instruction/Agent%E6%94%AF%E6%8C%81.html ç°å·²æ”¯æŒ500+å¤§æ¨¡å‹ä¸200+å¤šæ¨¡æ€å¤§æ¨¡å‹çš„è®­ç»ƒï¼ˆé¢„è®­ç»ƒã€å¾®è°ƒã€äººç±»å¯¹é½ï¼‰ã€æ¨ç†ã€è¯„æµ‹ã€é‡åŒ–ä¸éƒ¨ç½²ã€‚æ¨¡å‹å¼€å‘è€…å¯ä»¥åœ¨ms-swiftæ¡†æ¶ä¸­ä¸€ç«™å¼å®Œæˆå›´ç»•å¤§æ¨¡å‹çš„å„ç±»éœ€æ±‚
    
      
    
4. LlamaFactoryã€‚LLaMA-Factoryï¼Œæ— éœ€ç¼–å†™ä»£ç å³å¯è®­ç»ƒå’Œå¾®è°ƒå¼€æºLLMå’ŒVLMï¼Œæ”¯æŒ100å¤šç§æ¨¡å‹ã€å¤šæ¨¡æ€å¾®è°ƒã€PPOã€DPOã€å®éªŒè·Ÿè¸ªç­‰ã€‚åœ°å€ï¼šhttps://github.com/hiyouga/LLaMA-Factory



æ­¤å¤„å‘½åä¸º`æ•°æ®`ï¼Œä½†è¿™é‡Œå¹¶æ²¡æœ‰æä¾›å…·ä½“æ•°æ®é›†ï¼Œè€Œæ˜¯æä¾›äº†å¤„ç†è·å–å¤§è§„æ¨¡æ•°æ®çš„æ–¹æ³•

1. [AotoLabel](https://github.com/refuel-ai/autolabel): Label, clean and enrich text datasets with LLMs.
2. [LabelLLM](https://github.com/opendatalab/LabelLLM): The Open-Source Data Annotation Platform.
3. [data-juicer](https://github.com/modelscope/data-juicer): A one-stop data processing system to make data higher-quality, juicier, and more digestible for LLMs!
4. [OmniParser](https://github.com/jf-tech/omniparser): a native Golang ETL streaming parser and transform library for CSV, JSON, XML, EDI, text, etc.
5. [MinerU (`ğŸ”¥`)](https://github.com/opendatalab/MinerU): MinerU is a one-stop, open-source, high-quality data extraction tool, supports PDF/webpage/e-book extraction.
6. [PDF-Extract-Kit](https://github.com/opendatalab/PDF-Extract-Kit): A Comprehensive Toolkit for High-Quality PDF Content Extraction.
7. [Parsera](https://github.com/raznem/parsera): Lightweight library for scraping web-sites with LLMs.
8. [Sparrow](https://github.com/katanaml/sparrow): Sparrow is an innovative open-source solution for efficient data extraction and processing from various documents and images.
9. [Docling](https://github.com/DS4SD/docling): Get your documents ready for gen AI.
10. [GOT-OCR2.0](https://github.com/Ucas-HaoranWei/GOT-OCR2.0): OCR Model.
11. [LLM Decontaminator](https://github.com/lm-sys/llm-decontaminator): Rethinking Benchmark and Contamination for Language Models with Rephrased Samples.
12. [DataTrove](https://github.com/huggingface/datatrove): DataTrove is a library to process, filter and deduplicate text data at a very large scale.
13. [llm-swarm](https://github.com/huggingface/llm-swarm/tree/main/examples/textbooks): Generate large synthetic datasets likeÂ [Cosmopedia](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia).
14. [Distilabel](https://github.com/argilla-io/distilabel): Distilabel is a framework for synthetic data and AI feedback for engineers who need fast, reliable and scalable pipelines based on verified research papers.
15. [Common-Crawl-Pipeline-Creator](https://huggingface.co/spaces/lhoestq/Common-Crawl-Pipeline-Creator): The Common Crawl Pipeline Creator.
16. [Tabled](https://github.com/VikParuchuri/tabled): Detect and extract tables to markdown and csv.
17. [Zerox](https://github.com/getomni-ai/zerox): Zero shot pdf OCR with gpt-4o-mini.
18. [DocLayout-YOLO](https://github.com/opendatalab/DocLayout-YOLO): Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception.
19. [TensorZero](https://github.com/tensorzero/tensorzero): make LLMs improve through experience.
20. [Promptwright](https://github.com/StacklokLabs/promptwright): Generate large synthetic data using a local LLM.
21. [pdf-extract-api](https://github.com/CatchTheTornado/pdf-extract-api): Document (PDF) extraction and parse API using state of the art modern OCRs + Ollama supported models.
22. [pdf2htmlEX](https://github.com/pdf2htmlEX/pdf2htmlEX): Convert PDF to HTML without losing text or format.
23. [Extractous](https://github.com/yobix-ai/extractous): Fast and efficient unstructured data extraction. Written in Rust with bindings for many languages.
24. [MegaParse](https://github.com/QuivrHQ/MegaParse): File Parser optimised for LLM Ingestion with no loss.
25. [MarkItDown](https://github.com/microsoft/markitdown): Python tool for converting files and office documents to Markdown.
26. [datasketch](https://github.com/ekzhu/datasketch): datasketch gives you probabilistic data structures that can process and search very large amount of data super fast, with little loss of accuracy.
27. [semhash](https://github.com/MinishLab/semhash): lightweight and flexible tool for deduplicating datasets using semantic similarity.
28. [ReaderLM-v2](https://huggingface.co/jinaai/ReaderLM-v2): a 1.5B parameter language model that converts raw HTML into beautifully formatted markdown or JSON.
29. [Bespoke Curator](https://github.com/bespokelabsai/curator): Data Curation for Post-Training & Structured Data Extraction.
30. [LangKit](https://github.com/whylabs/langkit): An open-source toolkit for monitoring Large Language Models (LLMs). Extracts signals from prompts & responses, ensuring safety & security.
31. [Curator](https://github.com/bespokelabsai/curator): Synthetic Data curation for post-training and structured data extraction.
32. [olmOCR](https://github.com/allenai/olmocr): A toolkit for training language models to work with PDF documents in the wild.
33. [Easy Dataset (`ğŸ”¥`)](https://github.com/ConardLi/easy-dataset): A powerful tool for creating fine-tuning datasets for LLM.
34. [BabelDOC](https://github.com/funstory-ai/BabelDOC): PDF scientific paper translation and bilingual comparison library.
35. [Dolphin](https://github.com/bytedance/Dolphin): Document Image Parsing via Heterogeneous Anchor Prompting.
36. [EasyDistill](https://github.com/modelscope/easydistill): Easy Knowledge Distillation for Large Language Models.
37. [ContextGem](https://github.com/shcherbak-ai/contextgem): a free, open-source LLM framework that makes it radically easier to extract structured data and insights from documents.
38. [OCRFlux](https://github.com/chatdoc-com/OCRFlux): a lightweight yet powerful multimodal toolkit that significantly advances PDF-to-Markdown conversion, excelling in complex layout handling, complicated table parsing and cross-page content merging.
39. [DataFlow](https://github.com/OpenDCAI/DataFlow): Easy Data Preparation with latest LLMs-based Operators and Pipelines.
40. [DatasetLoom (`multimodal`)](https://github.com/599yongyang/DatasetLoom): ä¸€ä¸ªé¢å‘å¤šæ¨¡æ€å¤§æ¨¡å‹è®­ç»ƒçš„æ™ºèƒ½æ•°æ®é›†æ„å»ºä¸è¯„ä¼°å¹³å°.
41. [Logics-Parsing](https://github.com/alibaba/Logics-Parsing)
42. [DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR)
43. [PaddleOCR-VL](https://huggingface.co/PaddlePaddle/PaddleOCR-VL)
44. [Chandra](https://github.com/datalab-to/chandra): a highly accurate OCR model that converts images and PDFs into structured HTML/Markdown/JSON while preserving layout information.

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## å¾®è°ƒ Fine-Tuning

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E5%BE%AE%E8%B0%83-fine-tuning)

1. [LLaMA-Factory (`ğŸ”¥`)](https://github.com/hiyouga/LLaMA-Factory): Unify Efficient Fine-Tuning of 100+ LLMs.
2. [360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory): Unify Efficient Fine-Tuning of 100+ LLMs. (add Sequence Parallelism for supporting long context training)
3. [unsloth](https://github.com/unslothai/unsloth): 2-5X faster 80% less memory LLM finetuning.
4. [TRL](https://huggingface.co/docs/trl/index): Transformer Reinforcement Learning.
5. [Firefly](https://github.com/yangjianxin1/Firefly): Firefly: å¤§æ¨¡å‹è®­ç»ƒå·¥å…·ï¼Œæ”¯æŒè®­ç»ƒæ•°åç§å¤§æ¨¡å‹
6. [Xtuner](https://github.com/InternLM/xtuner): An efficient, flexible and full-featured toolkit for fine-tuning large models.
7. [torchtune](https://github.com/pytorch/torchtune): A Native-PyTorch Library for LLM Fine-tuning.
8. [Swift](https://github.com/modelscope/swift): Use PEFT or Full-parameter to finetune 200+ LLMs or 15+ MLLMs.
9. [AutoTrain](https://huggingface.co/autotrain): A new way to automatically train, evaluate and deploy state-of-the-art Machine Learning models.
10. [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF): An Easy-to-use, Scalable and High-performance RLHF Framework (Support 70B+ full tuning & LoRA & Mixtral & KTO).
11. [Ludwig](https://github.com/ludwig-ai/ludwig): Low-code framework for building custom LLMs, neural networks, and other AI models.
12. [mistral-finetune](https://github.com/mistralai/mistral-finetune): A light-weight codebase that enables memory-efficient and performant finetuning of Mistral's models.
13. [aikit](https://github.com/sozercan/aikit): Fine-tune, build, and deploy open-source LLMs easily!
14. [H2O-LLMStudio](https://github.com/h2oai/h2o-llmstudio): H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs.
15. [LitGPT](https://github.com/Lightning-AI/litgpt): Pretrain, finetune, deploy 20+ LLMs on your own data. Uses state-of-the-art techniques: flash attention, FSDP, 4-bit, LoRA, and more.
16. [LLMBox](https://github.com/RUCAIBox/LLMBox): A comprehensive library for implementing LLMs, including a unified training pipeline and comprehensive model evaluation.
17. [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP): Easy-to-use and powerful NLP and LLM library.
18. [workbench-llamafactory](https://github.com/NVIDIA/workbench-llamafactory): This is an NVIDIA AI Workbench example project that demonstrates an end-to-end model development workflow using Llamafactory.
19. [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF): An Easy-to-use, Scalable and High-performance RLHF Framework (70B+ PPO Full Tuning & Iterative DPO & LoRA & Mixtral).
20. [TinyLLaVA Factory](https://github.com/TinyLLaVA/TinyLLaVA_Factory): A Framework of Small-scale Large Multimodal Models.
21. [LLM-Foundry](https://github.com/mosaicml/llm-foundry): LLM training code for Databricks foundation models.
22. [lmms-finetune](https://github.com/zjysteven/lmms-finetune): A unified codebase for finetuning (full, lora) large multimodal models, supporting llava-1.5, qwen-vl, llava-interleave, llava-next-video, phi3-v etc.
23. [Simplifine](https://github.com/simplifine-llm/Simplifine): Simplifine lets you invoke LLM finetuning with just one line of code using any Hugging Face dataset or model.
24. [Transformer Lab](https://github.com/transformerlab/transformerlab-app): Open Source Application for Advanced LLM Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.
25. [Liger-Kernel](https://github.com/linkedin/Liger-Kernel): Efficient Triton Kernels for LLM Training.
26. [ChatLearn](https://github.com/alibaba/ChatLearn): A flexible and efficient training framework for large-scale alignment.
27. [nanotron](https://github.com/huggingface/nanotron): Minimalistic large language model 3D-parallelism training.
28. [Proxy Tuning](https://github.com/alisawuffles/proxy-tuning): Tuning Language Models by Proxy.
29. [Effective LLM Alignment](https://github.com/VikhrModels/effective_llm_alignment/): Effective LLM Alignment Toolkit.
30. [Autotrain-advanced](https://github.com/huggingface/autotrain-advanced)
31. [Meta Lingua](https://github.com/facebookresearch/lingua): a lean, efficient, and easy-to-hack codebase to research LLMs.
32. [Vision-LLM Alignemnt](https://github.com/NiuTrans/Vision-LLM-Alignment): This repository contains the code for SFT, RLHF, and DPO, designed for vision-based LLMs, including the LLaVA models and the LLaMA-3.2-vision models.
33. [finetune-Qwen2-VL](https://github.com/zhangfaen/finetune-Qwen2-VL): Quick Start for Fine-tuning or continue pre-train Qwen2-VL Model.
34. [Online-RLHF](https://github.com/RLHFlow/Online-RLHF): A recipe for online RLHF and online iterative DPO.
35. [InternEvo](https://github.com/InternLM/InternEvo): an open-sourced lightweight training framework aims to support model pre-training without the need for extensive dependencies.
36. [veRL](https://github.com/volcengine/verl): Volcano Engine Reinforcement Learning for LLM.
37. [Axolotl](https://axolotl-ai-cloud.github.io/axolotl/): Axolotl is designed to work with YAML config files that contain everything you need to preprocess a dataset, train or fine-tune a model, run model inference or evaluation, and much more.
38. [Oumi](https://github.com/oumi-ai/oumi): Everything you need to build state-of-the-art foundation models, end-to-end.
39. [Kiln](https://github.com/Kiln-AI/Kiln): The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.
40. [DeepSeek-671B-SFT-Guide](https://github.com/ScienceOne-AI/DeepSeek-671B-SFT-Guide): An open-source solution for full parameter fine-tuning of DeepSeek-V3/R1 671B, including complete code and scripts from training to inference, as well as some practical experiences and conclusions.
41. [MLX-VLM](https://github.com/Blaizzy/mlx-vlm): MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.
42. [RL-Factory](https://github.com/Simple-Efficient/RL-Factory): Train your Agent model via our easy and efficient framework.
43. [RM-Gallery](https://github.com/modelscope/RM-Gallery): A One-Stop Reward Model Platform.
44. [ART](https://github.com/OpenPipe/ART): rain multi-step agents for real-world tasks using GRPO. Give your agents on-the-job training.
45. [VeRL (`ğŸ”¥`)](https://github.com/volcengine/verl): Volcano Engine Reinforcement Learning for LLMs.
46. [LMMs-Engine](https://github.com/EvolvingLMMs-Lab/lmms-engine): A simple, any-to-any modality framework for pretraining and finetuning. Lean, flexible, and built for research.

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## æ¨ç† Inference

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%8E%A8%E7%90%86-inference)

1. [ollama](https://github.com/ollama/ollama): Get up and running with Llama 3, Mistral, Gemma, and other large language models.
2. [Open WebUI](https://github.com/open-webui/open-webui): User-friendly WebUI for LLMs (Formerly Ollama WebUI).
3. [Text Generation WebUI](https://github.com/oobabooga/text-generation-webui): A Gradio web UI for Large Language Models. Supports transformers, GPTQ, AWQ, EXL2, llama.cpp (GGUF), Llama models.
4. [Xinference](https://github.com/xorbitsai/inference): A powerful and versatile library designed to serve language, speech recognition, and multimodal models.
5. [LangChain](https://github.com/langchain-ai/langchain): Build context-aware reasoning applications.
6. [LlamaIndex](https://github.com/run-llama/llama_index): A data framework for your LLM applications.
7. [lobe-chat](https://github.com/lobehub/lobe-chat): an open-source, modern-design LLMs/AI chat framework. Supports Multi AI Providers, Multi-Modals (Vision/TTS) and plugin system.
8. [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM): TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.
9. [vllm (`ğŸ”¥`)](https://github.com/vllm-project/vllm): A high-throughput and memory-efficient inference and serving engine for LLMs.
10. [LlamaChat](https://github.com/alexrozanski/LlamaChat): Chat with your favourite LLaMA models in a native macOS app.
11. [NVIDIA ChatRTX](https://www.nvidia.com/en-us/ai-on-rtx/chatrtx/): ChatRTX is a demo app that lets you personalize a GPT large language model (LLM) connected to your own contentâ€”docs, notes, or other data.
12. [LM Studio](https://lmstudio.ai/): Discover, download, and run local LLMs.
13. [chat-with-mlx](https://github.com/qnguyen3/chat-with-mlx): Chat with your data natively on Apple Silicon using MLX Framework.
14. [LLM Pricing](https://llmpricecheck.com/): Quickly Find the Perfect Large Language Models (LLM) API for Your Budget! Use Our Free Tool for Instant Access to the Latest Prices from Top Providers.
15. [Open Interpreter](https://github.com/OpenInterpreter/open-interpreter): A natural language interface for computers.
16. [Chat-ollama](https://github.com/sugarforever/chat-ollama): An open source chatbot based on LLMs. It supports a wide range of language models, and knowledge base management.
17. [chat-ui](https://github.com/huggingface/chat-ui): Open source codebase powering the HuggingChat app.
18. [MemGPT](https://github.com/cpacker/MemGPT): Create LLM agents with long-term memory and custom tools.
19. [koboldcpp](https://github.com/LostRuins/koboldcpp): A simple one-file way to run various GGML and GGUF models with KoboldAI's UI.
20. [LLMFarm](https://github.com/guinmoon/LLMFarm): llama and other large language models on iOS and MacOS offline using GGML library.
21. [enchanted](https://github.com/AugustDev/enchanted): Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama.
22. [Flowise](https://github.com/FlowiseAI/Flowise): Drag & drop UI to build your customized LLM flow.
23. [Jan](https://github.com/janhq/jan): Jan is an open source alternative to ChatGPT that runs 100% offline on your computer. Multiple engine support (llama.cpp, TensorRT-LLM).
24. [LMDeploy](https://github.com/InternLM/lmdeploy): LMDeploy is a toolkit for compressing, deploying, and serving LLMs.
25. [RouteLLM](https://github.com/lm-sys/RouteLLM): A framework for serving and evaluating LLM routers - save LLM costs without compromising quality!
26. [MInference](https://github.com/microsoft/MInference): About To speed up Long-context LLMs' inference, approximate and dynamic sparse calculate the attention, which reduces inference latency by up to 10x for pre-filling on an A100 while maintaining accuracy.
27. [Mem0](https://github.com/mem0ai/mem0): The memory layer for Personalized AI.
28. [SGLang (`ğŸ”¥`)](https://github.com/sgl-project/sglang): SGLang is yet another fast serving framework for large language models and vision language models.
29. [AirLLM](https://github.com/lyogavin/airllm): AirLLM optimizes inference memory usage, allowing 70B large language models to run inference on a single 4GB GPU card without quantization, distillation and pruning. And you can run 405B Llama3.1 on 8GB vram now.
30. [LLMHub](https://github.com/jmather/llmhub): LLMHub is a lightweight management platform designed to streamline the operation and interaction with various language models (LLMs).
31. [YuanChat](https://github.com/IEIT-Yuan/YuanChat)
32. [LiteLLM](https://github.com/BerriAI/litellm): Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]
33. [GuideLLM](https://github.com/neuralmagic/guidellm): GuideLLM is a powerful tool for evaluating and optimizing the deployment of large language models (LLMs).
34. [LLM-Engines](https://github.com/jdf-prog/LLM-Engines): A unified inference engine for large language models (LLMs) including open-source models (VLLM, SGLang, Together) and commercial models (OpenAI, Mistral, Claude).
35. [OARC](https://github.com/Leoleojames1/ollama_agent_roll_cage): ollama_agent_roll_cage (OARC) is a local python agent fusing ollama llm's with Coqui-TTS speech models, Keras classifiers, Llava vision, Whisper recognition, and more to create a unified chatbot agent for local, custom automation.
36. [g1](https://github.com/bklieger-groq/g1): Using Llama-3.1 70b on Groq to create o1-like reasoning chains.
37. [MemoryScope](https://github.com/modelscope/MemoryScope): MemoryScope provides LLM chatbots with powerful and flexible long-term memory capabilities, offering a framework for building such abilities.
38. [OpenLLM](https://github.com/bentoml/OpenLLM): Run any open-source LLMs, such as Llama 3.1, Gemma, as OpenAI compatible API endpoint in the cloud.
39. [Infinity](https://github.com/infiniflow/infinity): The AI-native database built for LLM applications, providing incredibly fast hybrid search of dense embedding, sparse embedding, tensor and full-text.
40. [optillm](https://github.com/codelion/optillm): an OpenAI API compatible optimizing inference proxy which implements several state-of-the-art techniques that can improve the accuracy and performance of LLMs.
41. [LLaMA Box](https://github.com/gpustack/llama-box): LLM inference server implementation based on llama.cpp.
42. [ZhiLight](https://github.com/zhihu/ZhiLight): A highly optimized inference acceleration engine for Llama and its variants.
43. [DashInfer](https://github.com/modelscope/dash-infer): DashInfer is a native LLM inference engine aiming to deliver industry-leading performance atop various hardware architectures.
44. [LocalAI](https://github.com/mudler/LocalAI): The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required.
45. [ktransformers](https://github.com/kvcache-ai/ktransformers): A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations.
46. [SkyPilot](https://github.com/skypilot-org/skypilot): Run AI and batch jobs on any infra (Kubernetes or 14+ clouds). Get unified execution, cost savings, and high GPU availability via a simple interface.
47. [Chitu](https://github.com/thu-pacman/chitu): High-performance inference framework for large language models, focusing on efficiency, flexibility, and availability.
48. [TokenSwift](https://github.com/bigai-nlco/TokenSwift): From Hours to Minutes: Lossless Acceleration of Ultra Long Sequence Generation.
49. [Cherry Studio](https://github.com/CherryHQ/cherry-studio): a desktop client that supports for multiple LLM providers, available on Windows, Mac and Linux.
50. [Shimmy](https://github.com/Michael-A-Kuykendall/shimmy): Python-free Rust inference server â€” OpenAI-API compatible. GGUF + SafeTensors, hot model swap, auto-discovery, single binary.
51. [LlamaBarn](https://github.com/ggml-org/LlamaBarn): Run local LLMs on your Mac with a simple menu bar app.
52. [Parallax](https://github.com/GradientHQ/parallax): a distributed model serving framework that lets you build your own AI cluster anywhere.

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## è¯„ä¼° Evaluation

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E8%AF%84%E4%BC%B0-evaluation)

1. [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness): A framework for few-shot evaluation of language models.
2. [opencompass](https://github.com/open-compass/opencompass): OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.
3. [llm-comparator](https://github.com/PAIR-code/llm-comparator): LLM Comparator is an interactive data visualization tool for evaluating and analyzing LLM responses side-by-side, developed.
4. [EvalScope (`ğŸ”¥`)](https://github.com/modelscope/evalscope)
5. [Weave](https://weave-docs.wandb.ai/guides/core-types/evaluations): A lightweight toolkit for tracking and evaluating LLM applications.
6. [MixEval](https://github.com/Psycoy/MixEval/): Deriving Wisdom of the Crowd from LLM Benchmark Mixtures.
7. [Evaluation guidebook](https://github.com/huggingface/evaluation-guidebook): If you've ever wondered how to make sure an LLM performs well on your specific task, this guide is for you!
8. [Ollama Benchmark](https://github.com/aidatatools/ollama-benchmark): LLM Benchmark for Throughput via Ollama (Local LLMs).
9. [VLMEvalKit](https://github.com/open-compass/VLMEvalKit): Open-source evaluation toolkit of large vision-language models (LVLMs), support ~100 VLMs, 40+ benchmarks.
10. [AGI-Eval](https://agi-eval.cn/mvp/home)
11. [EvalScope](https://github.com/modelscope/evalscope): A streamlined and customizable framework for efficient large model evaluation and performance benchmarking.
12. [DeepEval](https://github.com/confident-ai/deepeval): a simple-to-use, open-source LLM evaluation framework, for evaluating and testing large-language model systems.
13. [Lighteval](https://github.com/huggingface/lighteval): Lighteval is your all-in-one toolkit for evaluating LLMs across multiple backends.
14. [QwQ/eval](https://github.com/QwenLM/QwQ/tree/main/eval): QwQ is the reasoning model series developed by Qwen team, Alibaba Cloud.
15. [Evalchemy](https://github.com/mlfoundations/evalchemy): A unified and easy-to-use toolkit for evaluating post-trained language models.
16. [MathArena](https://github.com/eth-sri/matharena): Evaluation of LLMs on latest math competitions.
17. [YourBench](https://github.com/huggingface/yourbench): A Dynamic Benchmark Generation Framework.
18. [MedEvalKit](https://github.com/alibaba-damo-academy/MedEvalKit): A Unified Medical Evaluation Framework.

`LLM API æœåŠ¡å¹³å°`ï¼š

1. [Groq](https://groq.com/)
2. [ç¡…åŸºæµåŠ¨](https://cloud.siliconflow.cn/models)
3. [ç«å±±å¼•æ“](https://www.volcengine.com/product/ark)
4. [æ–‡å¿ƒåƒå¸†](https://qianfan.cloud.baidu.com/)
5. [DashScope](https://dashscope.aliyun.com/)
6. [aisuite](https://github.com/andrewyng/aisuite)
7. [DeerAPI](https://www.deerapi.com/)
8. [Qwen-Chat](https://chat.qwenlm.ai/)
9. [DeepSeek-v3](https://www.deepseek.com/)
10. [WaveSpeed](https://wavespeed.ai/)Â `è§†é¢‘ç”Ÿæˆ`
11. [OpenRouter](https://openrouter.ai/)
12. [æ•°æ ‡æ ‡ (`ğŸ”¥`)](https://api.ai-gaochao.cn/)
13. [WaveSpeed](https://wavespeed.ai/)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## ä½“éªŒ Usage

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E4%BD%93%E9%AA%8C-usage)

1. [LMSYS Chatbot Arena: Benchmarking LLMs in the Wild](https://arena.lmsys.org/)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## çŸ¥è¯†åº“ RAG

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E7%9F%A5%E8%AF%86%E5%BA%93-rag)

1. [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm): The all-in-one AI app for any LLM with full RAG and AI Agent capabilites.
2. [MaxKB](https://github.com/1Panel-dev/MaxKB): åŸºäº LLM å¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿã€‚å¼€ç®±å³ç”¨ï¼Œæ”¯æŒå¿«é€ŸåµŒå…¥åˆ°ç¬¬ä¸‰æ–¹ä¸šåŠ¡ç³»ç»Ÿ
3. [RAGFlow](https://github.com/infiniflow/ragflow): An open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.
4. [Dify](https://github.com/langgenius/dify): An open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.
5. [FastGPT](https://github.com/labring/FastGPT): A knowledge-based platform built on the LLM, offers out-of-the-box data processing and model invocation capabilities, allows for workflow orchestration through Flow visualization.
6. [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat): åŸºäº Langchain ä¸ ChatGLM ç­‰ä¸åŒå¤§è¯­è¨€æ¨¡å‹çš„æœ¬åœ°çŸ¥è¯†åº“é—®ç­”
7. [QAnything](https://github.com/netease-youdao/QAnything): Question and Answer based on Anything.
8. [Quivr](https://github.com/QuivrHQ/quivr): A personal productivity assistant (RAG) âš¡ï¸ğŸ¤– Chat with your docs (PDF, CSV, ...) & apps using Langchain, GPT 3.5 / 4 turbo, Private, Anthropic, VertexAI, Ollama, LLMs, Groq that you can share with users ! Local & Private alternative to OpenAI GPTs & ChatGPT powered by retrieval-augmented generation.
9. [RAG-GPT](https://github.com/open-kf/rag-gpt): RAG-GPT, leveraging LLM and RAG technology, learns from user-customized knowledge bases to provide contextually relevant answers for a wide range of queries, ensuring rapid and accurate information retrieval.
10. [Verba](https://github.com/weaviate/Verba): Retrieval Augmented Generation (RAG) chatbot powered by Weaviate.
11. [FlashRAG](https://github.com/RUC-NLPIR/FlashRAG): A Python Toolkit for Efficient RAG Research.
12. [GraphRAG](https://github.com/microsoft/graphrag): A modular graph-based Retrieval-Augmented Generation (RAG) system.
13. [LightRAG](https://github.com/SylphAI-Inc/LightRAG): LightRAG helps developers with both building and optimizing Retriever-Agent-Generator pipelines.
14. [GraphRAG-Ollama-UI](https://github.com/severian42/GraphRAG-Ollama-UI): GraphRAG using Ollama with Gradio UI and Extra Features.
15. [nano-GraphRAG](https://github.com/gusye1234/nano-graphrag): A simple, easy-to-hack GraphRAG implementation.
16. [RAG Techniques](https://github.com/NirDiamant/RAG_Techniques): This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.
17. [ragas](https://github.com/explodinggradients/ragas): Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines.
18. [kotaemon](https://github.com/Cinnamon/kotaemon): An open-source clean & customizable RAG UI for chatting with your documents. Built with both end users and developers in mind.
19. [RAGapp](https://github.com/ragapp/ragapp): The easiest way to use Agentic RAG in any enterprise.
20. [TurboRAG](https://github.com/MooreThreads/TurboRAG): Accelerating Retrieval-Augmented Generation with Precomputed KV Caches for Chunked Text.
21. [LightRAG](https://github.com/HKUDS/LightRAG): Simple and Fast Retrieval-Augmented Generation.
22. [TEN](https://github.com/TEN-framework/ten_framework): the Next-Gen AI-Agent Framework, the world's first truly real-time multimodal AI agent framework.
23. [AutoRAG](https://github.com/Marker-Inc-Korea/AutoRAG): RAG AutoML tool for automatically finding an optimal RAG pipeline for your data.
24. [KAG](https://github.com/OpenSPG/KAG): KAG is a knowledge-enhanced generation framework based on OpenSPG engine, which is used to build knowledge-enhanced rigorous decision-making and information retrieval knowledge services.
25. [Fast-GraphRAG](https://github.com/circlemind-ai/fast-graphrag): RAG that intelligently adapts to your use case, data, and queries.
26. [Tiny-GraphRAG](https://github.com/limafang/tiny-graphrag)
27. [DB-GPT GraphRAG](https://github.com/eosphoros-ai/DB-GPT/tree/main/dbgpt/storage/knowledge_graph): DB-GPT GraphRAG integrates both triplet-based knowledge graphs and document structure graphs while leveraging community and document retrieval mechanisms to enhance RAG capabilities, achieving comparable performance while consuming only 50% of the tokens required by Microsoft's GraphRAG. Refer to the DB-GPTÂ [Graph RAG User Manual](http://docs.dbgpt.cn/docs/cookbook/rag/graph_rag_app_develop/)Â for details.
28. [Chonkie](https://github.com/bhavnicksm/chonkie): The no-nonsense RAG chunking library that's lightweight, lightning-fast, and ready to CHONK your texts.
29. [RAGLite](https://github.com/superlinear-ai/raglite): RAGLite is a Python toolkit for Retrieval-Augmented Generation (RAG) with PostgreSQL or SQLite.
30. [KAG](https://github.com/OpenSPG/KAG): KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.
31. [CAG](https://github.com/hhhuang/CAG): CAG leverages the extended context windows of modern large language models (LLMs) by preloading all relevant resources into the modelâ€™s context and caching its runtime parameters.
32. [MiniRAG](https://github.com/HKUDS/MiniRAG): an extremely simple retrieval-augmented generation framework that enables small models to achieve good RAG performance through heterogeneous graph indexing and lightweight topology-enhanced retrieval.
33. [XRAG](https://github.com/DocAILab/XRAG): a benchmarking framework designed to evaluate the foundational components of advanced Retrieval-Augmented Generation (RAG) systems.
34. [Rankify](https://github.com/DataScienceUIBK/rankify): A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation.
35. [RAG-Anything](https://github.com/HKUDS/RAG-Anything): All-in-One RAG System.

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## æ™ºèƒ½ä½“ Agents

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%99%BA%E8%83%BD%E4%BD%93-agents)

1. [AutoGen](https://github.com/microsoft/autogen): AutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks.Â [AutoGen AIStudio](https://autogen-studio.com/)
2. [CrewAI](https://github.com/joaomdmoura/crewAI): Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.
3. [Coze](https://www.coze.com/)
4. [AgentGPT](https://github.com/reworkd/AgentGPT): Assemble, configure, and deploy autonomous AI Agents in your browser.
5. [XAgent](https://github.com/OpenBMB/XAgent): An Autonomous LLM Agent for Complex Task Solving.
6. [MobileAgent](https://github.com/X-PLUG/MobileAgent): The Powerful Mobile Device Operation Assistant Family.
7. [Lagent](https://github.com/InternLM/lagent): A lightweight framework for building LLM-based agents.
8. [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent): Agent framework and applications built upon Qwen2, featuring Function Calling, Code Interpreter, RAG, and Chrome extension.
9. [LinkAI](https://link-ai.tech/portal): ä¸€ç«™å¼ AI æ™ºèƒ½ä½“æ­å»ºå¹³å°
10. [Baidu APPBuilder](https://appbuilder.cloud.baidu.com/)
11. [agentUniverse](https://github.com/alipay/agentUniverse): agentUniverse is a LLM multi-agent framework that allows developers to easily build multi-agent applications. Furthermore, through the community, they can exchange and share practices of patterns across different domains.
12. [LazyLLM](https://github.com/LazyAGI/LazyLLM): ä½ä»£ç æ„å»ºå¤šAgentå¤§æ¨¡å‹åº”ç”¨çš„å¼€å‘å·¥å…·
13. [AgentScope](https://github.com/modelscope/agentscope): Start building LLM-empowered multi-agent applications in an easier way.
14. [MoA](https://github.com/togethercomputer/MoA): Mixture of Agents (MoA) is a novel approach that leverages the collective strengths of multiple LLMs to enhance performance, achieving state-of-the-art results.
15. [Agently](https://github.com/Maplemx/Agently): AI Agent Application Development Framework.
16. [OmAgent](https://github.com/om-ai-lab/OmAgent): A multimodal agent framework for solving complex tasks.
17. [Tribe](https://github.com/StreetLamb/tribe): No code tool to rapidly build and coordinate multi-agent teams.
18. [CAMEL](https://github.com/camel-ai/camel): First LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents.
19. [PraisonAI](https://github.com/MervinPraison/PraisonAI/): PraisonAI application combines AutoGen and CrewAI or similar frameworks into a low-code solution for building and managing multi-agent LLM systems, focusing on simplicity, customisation, and efficient human-agent collaboration.
20. [IoA](https://github.com/openbmb/ioa): An open-source framework for collaborative AI agents, enabling diverse, distributed agents to team up and tackle complex tasks through internet-like connectivity.
21. [llama-agentic-system](https://github.com/meta-llama/llama-agentic-system)Â : Agentic components of the Llama Stack APIs.
22. [Agent Zero](https://github.com/frdel/agent-zero): Agent Zero is not a predefined agentic framework. It is designed to be dynamic, organically growing, and learning as you use it.
23. [Agents](https://github.com/aiwaves-cn/agents): An Open-source Framework for Data-centric, Self-evolving Autonomous Language Agents.
24. [AgentScope](https://github.com/modelscope/agentscope): Start building LLM-empowered multi-agent applications in an easier way.
25. [FastAgency](https://github.com/airtai/fastagency): The fastest way to bring multi-agent workflows to production.
26. [Swarm](https://github.com/openai/swarm): Framework for building, orchestrating and deploying multi-agent systems. Managed by OpenAI Solutions team. Experimental framework.
27. [Agent-S](https://github.com/simular-ai/Agent-S): an open agentic framework that uses computers like a human.
28. [PydanticAI](https://github.com/pydantic/pydantic-ai): Agent Framework / shim to use Pydantic with LLMs.
29. [Agentarium](https://github.com/Thytu/Agentarium): open-source framework for creating and managing simulations populated with AI-powered agents.
30. [smolagents](https://github.com/huggingface/smolagents): a barebones library for agents. Agents write python code to call tools and orchestrate other agents.
31. [Cooragent](https://github.com/LeapLabTHU/cooragent): Cooragent is an AI agent collaboration community.
32. [Agno](https://github.com/agno-agi/agno): Agno is a lightweight library for building Agents with memory, knowledge, tools and reasoning.
33. [Suna](https://github.com/kortix-ai/suna): Open Source Generalist AI Agent.
34. [rowboat](https://github.com/rowboatlabs/rowboat): Let AI build multi-agent workflows for you in minutes.
35. [EvoAgentX](https://github.com/EvoAgentX/EvoAgentX): Building a Self-Evolving Ecosystem of AI Agents.
36. [ii-agent](https://github.com/Intelligent-Internet/ii-agent): a new open-source framework to build and deploy intelligent agents.
37. [OWL](https://github.com/camel-ai/owl): Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation.
38. [OpenManus](https://github.com/FoundationAgents/OpenManus): No fortress, purely open ground. OpenManus is Coming.
39. [JoyAgent-JDGenie](https://github.com/jd-opensource/joyagent-jdgenie): ä¸šç•Œé¦–ä¸ªå¼€æºé«˜å®Œæˆåº¦è½»é‡åŒ–é€šç”¨å¤šæ™ºèƒ½ä½“äº§å“.
40. [coze-studio](https://github.com/coze-dev/coze-studio): An AI agent development platform with all-in-one visual tools, simplifying agent creation, debugging, and deployment like never before.
41. [OxyGent](https://github.com/jd-opensource/OxyGent): An advanced Python framework that empowers developers to quickly build production-ready intelligent systems.
42. [LazyCraft](https://github.com/LazyAGI/LazyCraft): LazyCraft æ˜¯ä¸€ä¸ªåŸºäº LazyLLM æ„å»ºçš„ AI Agent åº”ç”¨å¼€å‘ä¸ç®¡ç†å¹³å°ï¼Œæ—¨åœ¨ååŠ©å¼€å‘è€…ä»¥ ä½é—¨æ§›ã€ä½æˆæœ¬ å¿«é€Ÿæ„å»ºå’Œå‘å¸ƒå¤§æ¨¡å‹åº”ç”¨ã€‚
43. [OpenAgents](https://github.com/openagents-org/openagents): AI Agent Networks for Open Collaboration.
44. [SandBox](https://github.com/agent-infra/sandbox): All-in-One Sandbox for AI Agents that combines Browser, Shell, File, MCP and VSCode Server in a single Docker container.
45. [DeepAnalyze](https://github.com/ruc-datalab/DeepAnalyze): First agentic LLM for autonomous data science, supporting specific data tasks (data preparation, analysis, modeling, visualization, and insight) and data-oriented deep research (produce analyst-grade research reports).
46. [Astron Agent](https://github.com/iflytek/astron-agent): Enterprise-grade, commercial-friendly agentic workflow platform for building next-generation SuperAgents.

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## ä»£ç  Coding

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E4%BB%A3%E7%A0%81-coding)

1. [Cloi CLI](https://github.com/cloi-ai/cloi): Local debugging agent that runs in your terminal.
2. [Devin](https://devin.ai/)
3. [v0](https://v0.dev/)
4. [Blot.new](https://bolt.new/)
5. [cursor](https://www.cursor.com/)
6. [Windsurf](https://codeium.com/windsurf)
7. [cline](https://github.com/cline/cline)
8. [Trae](https://www.trae.ai/)
9. [MGX](https://mgx.dev/)
10. [Roo Code](https://github.com/RooCodeInc/Roo-Code)
11. [Kilo Code](https://github.com/Kilo-Org/kilocode)
12. [AugmentCode](https://www.augmentcode.com/)
13. [Claude Code](https://github.com/anthropics/claude-code)
14. [Gemini CLI](https://github.com/google-gemini/gemini-cli)
15. [Serena](https://github.com/oraios/serena)
16. [Claudia](https://github.com/getAsterisk/claudia)
17. [OpenCode](https://github.com/opencode-ai/opencode)
18. [Kiro](https://kiro.dev/)
19. [CodeBuddy](https://copilot.tencent.com/)
20. [Kiro](https://kiro.dev/)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## è§†é¢‘ Video

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E8%A7%86%E9%A2%91-video)

#### æ¨¡å‹

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%A8%A1%E5%9E%8B)

Note

ğŸ¤[Awesome-Video-Diffusion](https://github.com/showlab/Awesome-Video-Diffusion)

1. [HunyuanVideo](https://github.com/Tencent/HunyuanVideo)
2. [CogVideo](https://github.com/THUDM/CogVideo)
3. [Wan2.1](https://github.com/Wan-Video/Wan2.1)
4. [Open-Sora](https://github.com/hpcaitech/Open-Sora)
5. [Open-Sora-Plan](https://github.com/PKU-YuanGroup/Open-Sora-Plan)
6. [LTX-Video](https://github.com/Lightricks/LTX-Video)
7. [Step-Video-T2V](https://github.com/stepfun-ai/Step-Video-T2V)
8. [Step1X-Edit](https://github.com/stepfun-ai/Step1X-Edit)Â `Editing`
9. [Wan2.1-VACE](https://huggingface.co/Wan-AI/Wan2.1-VACE-14B)Â `Editing`
10. [ICEdit](https://github.com/River-Zhang/ICEdit)Â `Editing`
11. [mochi-1-preview](https://huggingface.co/genmo/mochi-1-preview)
12. [Wan2.1-Fun](https://huggingface.co/collections/alibaba-pai/wan21-fun-v11-680f514c89fe7b4df9d44f17)
13. [Wan2.1-FLF2V](https://huggingface.co/Wan-AI/Wan2.1-FLF2V-14B-720P)Â `é¦–å°¾å¸§`
14. [MAGI-1](https://github.com/SandAI-org/MAGI-1)Â `è‡ªå›å½’æ¨¡å‹`
15. [SkyReels-V2](https://github.com/SkyworkAI/SkyReels-V2)
16. [FramePack](https://github.com/lllyasviel/FramePack)
17. [Pusa-VidGen](https://github.com/Yaofang-Liu/Pusa-VidGen)
18. [Wan2.2](https://github.com/Wan-Video/Wan2.2)
19. [MoGA](https://arxiv.org/pdf/2510.18692)Â `é•¿è§†é¢‘`
20. [LongCat-Video](https://huggingface.co/meituan-longcat/LongCat-Video)

#### ç¼–è¾‘

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E7%BC%96%E8%BE%91)

1. Wan2.1-VACE-14B:Â [https://huggingface.co/Wan-AI/Wan2.1-VACE-14B](https://huggingface.co/Wan-AI/Wan2.1-VACE-14B)
2. Ditto:Â [https://github.com/EzioBy/Ditto](https://github.com/EzioBy/Ditto)

#### è®­ç»ƒ

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E8%AE%AD%E7%BB%83)

- [https://github.com/hao-ai-lab/FastVideo](https://github.com/hao-ai-lab/FastVideo)
- [https://github.com/tdrussell/diffusion-pipe](https://github.com/tdrussell/diffusion-pipe)
- [https://github.com/VideoVerses/VideoTuna](https://github.com/VideoVerses/VideoTuna)
- [https://github.com/modelscope/DiffSynth-Studio](https://github.com/modelscope/DiffSynth-Studio)
- [https://github.com/huggingface/diffusers](https://github.com/huggingface/diffusers)
- [https://github.com/kohya-ss/musubi-tuner](https://github.com/kohya-ss/musubi-tuner)
- [https://github.com/spacepxl/HunyuanVideo-Training](https://github.com/spacepxl/HunyuanVideo-Training)
- [https://github.com/Tele-AI/TeleTron](https://github.com/Tele-AI/TeleTron)
- [https://github.com/Yaofang-Liu/Mochi-Full-Finetuner](https://github.com/Yaofang-Liu/Mochi-Full-Finetuner)
- [https://github.com/bghira/SimpleTuner](https://github.com/bghira/SimpleTuner)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## å›¾ç‰‡ Image

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E5%9B%BE%E7%89%87-image)

#### æ¨¡å‹

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%A8%A1%E5%9E%8B-1)

- [awesome-nano-banana](https://github.com/JimmyLv/awesome-nano-banana)
- [Awesome-Nano-Banana-images](https://github.com/PicoTrex/Awesome-Nano-Banana-images)
- HunyuanImage-3.0ï¼š[https://github.com/Tencent-Hunyuan/HunyuanImage-3.0](https://github.com/Tencent-Hunyuan/HunyuanImage-3.0)
- Seedream 4.0ï¼š[https://arxiv.org/abs/2509.20427](https://arxiv.org/abs/2509.20427)

#### ç¼–è¾‘

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E7%BC%96%E8%BE%91-1)

- ChronoEdit-14B:Â [https://huggingface.co/nvidia/ChronoEdit-14B-Diffusers](https://huggingface.co/nvidia/ChronoEdit-14B-Diffusers)

#### è®­ç»ƒ

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E8%AE%AD%E7%BB%83-1)

- Ostrisï¼š[https://github.com/ostris/ai-toolkit](https://github.com/ostris/ai-toolkit)
- FlymyAIï¼š[https://github.com/FlyMyAI/flymyai-lora-trainer](https://github.com/FlyMyAI/flymyai-lora-trainer)
- Nitro-Tï¼š[https://github.com/AMD-AGI/Nitro-T](https://github.com/AMD-AGI/Nitro-T)
- DiffSynth-Studioï¼š[https://github.com/modelscope/DiffSynth-Studio](https://github.com/modelscope/DiffSynth-Studio)
- Musubi Tuner:Â [https://github.com/kohya-ss/musubi-tuner](https://github.com/kohya-ss/musubi-tuner)

#### è¯„ä¼°

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E8%AF%84%E4%BC%B0)

- ULMEvalKitï¼š[https://github.com/ULMEvalKit/ULMEvalKit](https://github.com/ULMEvalKit/ULMEvalKit)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## æœç´¢ Search

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%90%9C%E7%B4%A2-search)

1. [OpenSearch GPT](https://github.com/supermemoryai/opensearch-ai): SearchGPT / Perplexity clone, but personalised for you.
2. [MindSearch](https://github.com/InternLM/MindSearch): An LLM-based Multi-agent Framework of Web Search Engine (like Perplexity.ai Pro and SearchGPT).
3. [nanoPerplexityAI](https://github.com/Yusuke710/nanoPerplexityAI): The simplest open-source implementation of perplexity.ai.
4. [curiosity](https://github.com/jank/curiosity): Try to build a Perplexity-like user experience.
5. [MiniPerplx](https://github.com/zaidmukaddam/miniperplx): A minimalistic AI-powered search engine that helps you find information on the internet.

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## è¯­éŸ³ Speech

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E8%AF%AD%E9%9F%B3-speech)

#### TTS

[](https://github.com/WangRongsheng/awesome-LLM-resources#tts)

1. SpeechGPT-2.0-preview:Â [https://github.com/OpenMOSS/SpeechGPT-2.0-preview](https://github.com/OpenMOSS/SpeechGPT-2.0-preview)
2. Moss-TTSDï¼š[https://github.com/OpenMOSS/MOSS-TTSD](https://github.com/OpenMOSS/MOSS-TTSD)
3. Index-TTSï¼š[https://github.com/index-tts/index-tts](https://github.com/index-tts/index-tts)
4. MegaTTS3ï¼š[https://github.com/bytedance/MegaTTS3](https://github.com/bytedance/MegaTTS3)
5. F5-TTSï¼š[https://github.com/SWivid/F5-TTS](https://github.com/SWivid/F5-TTS)
6. GPT-SoVITSï¼š[https://github.com/RVC-Boss/GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)
7. CosyVoiceï¼š[https://github.com/FunAudioLLM/CosyVoice](https://github.com/FunAudioLLM/CosyVoice)
8. Spark-TTSï¼š[https://github.com/SparkAudio/Spark-TTS](https://github.com/SparkAudio/Spark-TTS)
9. OpenVoiceï¼š[https://github.com/myshell-ai/OpenVoice](https://github.com/myshell-ai/OpenVoice)
10. Diaï¼š[https://github.com/nari-labs/dia](https://github.com/nari-labs/dia)
11. ChatTTSï¼š[https://github.com/2noise/ChatTTS](https://github.com/2noise/ChatTTS)
12. Fish Speechï¼š[https://github.com/fishaudio/fish-speech](https://github.com/fishaudio/fish-speech)
13. Edge-TTSï¼š[https://github.com/rany2/edge-tts](https://github.com/rany2/edge-tts)
14. Barkï¼š[https://github.com/suno-ai/bark](https://github.com/suno-ai/bark)
15. kokoro:Â [https://github.com/hexgrad/kokoro](https://github.com/hexgrad/kokoro)
16. Higgs Audio V2:Â [https://github.com/boson-ai/higgs-audio](https://github.com/boson-ai/higgs-audio)Â ã€[Training](https://github.com/JimmyMa99/train-higgs-audio)ã€‘
17. KittenTTS:Â [https://github.com/KittenML/KittenTTS](https://github.com/KittenML/KittenTTS)
18. ZipVoice:Â [https://github.com/k2-fsa/ZipVoice](https://github.com/k2-fsa/ZipVoice)
19. VyvoTTS:Â [https://github.com/Vyvo-Labs/VyvoTTS](https://github.com/Vyvo-Labs/VyvoTTS)
20. VibeVoice:Â [https://github.com/microsoft/VibeVoice](https://github.com/microsoft/VibeVoice)
21. Index-TTS-2:Â [https://huggingface.co/IndexTeam/IndexTTS-2](https://huggingface.co/IndexTeam/IndexTTS-2)
22. FireRedTTS2:Â [https://github.com/FireRedTeam/FireRedTTS2](https://github.com/FireRedTeam/FireRedTTS2)
23. VoxCPM:Â [https://github.com/OpenBMB/VoxCPM/](https://github.com/OpenBMB/VoxCPM/)
24. Neutts-Air:Â [https://github.com/neuphonic/neutts-air](https://github.com/neuphonic/neutts-air)

#### STT

[](https://github.com/WangRongsheng/awesome-LLM-resources#stt)

1. Kyutai:Â [https://github.com/kyutai-labs/delayed-streams-modeling](https://github.com/kyutai-labs/delayed-streams-modeling)
2. Whisper:Â [https://github.com/openai/whisper](https://github.com/openai/whisper)
3. Audio Flamingo 3:Â [https://huggingface.co/nvidia/audio-flamingo-3](https://huggingface.co/nvidia/audio-flamingo-3)
4. Voxtral:Â [https://huggingface.co/mistralai/Voxtral-Mini-3B-2507](https://huggingface.co/mistralai/Voxtral-Mini-3B-2507)
5. Step-Audio2:Â [https://github.com/stepfun-ai/Step-Audio2](https://github.com/stepfun-ai/Step-Audio2)
6. SoulX-Podcast:Â [https://huggingface.co/collections/Soul-AILab/soulx-podcast](https://huggingface.co/collections/Soul-AILab/soulx-podcast)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## ç»Ÿä¸€æ¨¡å‹ Unified Model

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E7%BB%9F%E4%B8%80%E6%A8%A1%E5%9E%8B-unified-model)

> ç°åœ¨ç»Ÿä¸€æ¨¡å‹å·²ç»ä»`ç†è§£+ç”Ÿæˆ`å˜æˆ`ç†è§£+ç”Ÿæˆ+ç¼–è¾‘`

- Emu-2ï¼š[https://arxiv.org/abs/2312.13286](https://arxiv.org/abs/2312.13286)
- Emu-3ï¼š[https://arxiv.org/abs/2409.18869](https://arxiv.org/abs/2409.18869)
- Emu-1ï¼š[https://arxiv.org/abs/2307.05222](https://arxiv.org/abs/2307.05222)
- Janusï¼š[https://github.com/deepseek-ai/Janus](https://github.com/deepseek-ai/Janus)
- Janus-Proï¼š[http://arxiv.org/abs/2508.05954](http://arxiv.org/abs/2508.05954)
- show-oï¼š[https://arxiv.org/abs/2408.12528](https://arxiv.org/abs/2408.12528)
- Any-GPTï¼š[https://arxiv.org/abs/2402.12226](https://arxiv.org/abs/2402.12226)
- Next-GPTï¼š[https://arxiv.org/pdf/2309.05519.pdf](https://arxiv.org/pdf/2309.05519.pdf)
- CoDiï¼š[https://arxiv.org/abs/2305.11846](https://arxiv.org/abs/2305.11846)
- Seed-Xï¼š[https://arxiv.org/abs/2404.14396](https://arxiv.org/abs/2404.14396)
- Dream-LLMï¼š[https://arxiv.org/abs/2309.11499](https://arxiv.org/abs/2309.11499)
- Chameleonï¼š[https://arxiv.org/abs/2405.09818](https://arxiv.org/abs/2405.09818)
- Spiderï¼š[https://arxiv.org/abs/2411.09439](https://arxiv.org/abs/2411.09439)
- MedViLaMï¼š[https://arxiv.org/abs/2409.19684](https://arxiv.org/abs/2409.19684)
- VITRONï¼š[https://github.com/SkyworkAI/Vitron](https://github.com/SkyworkAI/Vitron)
- TokenFlowï¼š[https://github.com/ByteFlow-AI/TokenFlow](https://github.com/ByteFlow-AI/TokenFlow)
- OneDiffusionï¼š[https://github.com/lehduong/OneDiffusion](https://github.com/lehduong/OneDiffusion)
- MetaMorph:Â [https://arxiv.org/abs/2412.14164](https://arxiv.org/abs/2412.14164)
- LlamaFusionï¼š[https://arxiv.org/abs/2412.15188](https://arxiv.org/abs/2412.15188)
- InstructSegï¼š[https://arxiv.org/abs/2412.14006](https://arxiv.org/abs/2412.14006)
- VILA-Uï¼š[https://arxiv.org/abs/2409.04429](https://arxiv.org/abs/2409.04429)
- Ullava:Â [https://github.com/OPPOMKLab/u-LLaVA](https://github.com/OPPOMKLab/u-LLaVA)
- ILLUME:Â [https://arxiv.org/abs/2412.06673](https://arxiv.org/abs/2412.06673)
- Vitron:[https://arxiv.org/abs/2412.19806](https://arxiv.org/abs/2412.19806)
- SynerGen-VLï¼š[https://arxiv.org/abs/2412.09604](https://arxiv.org/abs/2412.09604)
- Align Anythingï¼š[https://arxiv.org/abs/2412.15838](https://arxiv.org/abs/2412.15838)
- Micoï¼š[https://arxiv.org/abs/2406.09412](https://arxiv.org/abs/2406.09412)
- OneLLM:[https://arxiv.org/abs/2312.03700](https://arxiv.org/abs/2312.03700)
- X-VILA:[https://arxiv.org/abs/2405.19335](https://arxiv.org/abs/2405.19335)
- OLAï¼š[https://arxiv.org/abs/2502.04328](https://arxiv.org/abs/2502.04328)
- Transfusion:Â [https://arxiv.org/abs/2408.11039](https://arxiv.org/abs/2408.11039)
- JanusFlow:Â [https://arxiv.org/abs/2411.07975](https://arxiv.org/abs/2411.07975)
- HealthGPTï¼š[https://arxiv.org/abs/2502.09838](https://arxiv.org/abs/2502.09838)Â `Medical`
- BAGELï¼š[https://arxiv.org/abs/2505.14683](https://arxiv.org/abs/2505.14683)
- Qwen2.5-Omniï¼š[https://arxiv.org/abs/2503.20215](https://arxiv.org/abs/2503.20215)
- X2Iï¼š[https://arxiv.org/abs/2503.06134](https://arxiv.org/abs/2503.06134)
- Bifrost-1ï¼š[https://arxiv.org/abs/2508.05954](https://arxiv.org/abs/2508.05954)
- OmniGen2ï¼š[https://arxiv.org/abs/2506.18871](https://arxiv.org/abs/2506.18871)
- UniPicï¼š[https://github.com/SkyworkAI/UniPic](https://github.com/SkyworkAI/UniPic)
- VeOmniï¼š[https://github.com/ByteDance-Seed/VeOmni](https://github.com/ByteDance-Seed/VeOmni)Â `Training`
- NextStep-1ï¼š[https://arxiv.org/abs/2508.10711](https://arxiv.org/abs/2508.10711)
- UniUGG:Â [https://arxiv.org/abs/2508.11952](https://arxiv.org/abs/2508.11952)Â `3D`
- Omni-Videoï¼š[https://arxiv.org/abs/2507.06119](https://arxiv.org/abs/2507.06119)
- OneCATï¼š[https://arxiv.org/abs/2509.03498](https://arxiv.org/abs/2509.03498)
- Lumina-DiMOOï¼š[https://github.com/Alpha-VLLM/Lumina-DiMOO](https://github.com/Alpha-VLLM/Lumina-DiMOO)
- UAEï¼š[https://github.com/PKU-YuanGroup/UAE](https://github.com/PKU-YuanGroup/UAE)
- RecAï¼š[https://arxiv.org/abs/2509.07295](https://arxiv.org/abs/2509.07295)
- UniLMï¼š[https://arxiv.org/abs/1905.03197](https://arxiv.org/abs/1905.03197)
- Hyper-Bagelï¼š[https://arxiv.org/abs/2509.18824](https://arxiv.org/abs/2509.18824)
- Ming-UniVisionï¼š[https://arxiv.org/abs/2510.06590](https://arxiv.org/abs/2510.06590)
- EditVerseï¼š[https://arxiv.org/abs/2509.20360](https://arxiv.org/abs/2509.20360)
- LightBagel:Â [https://arxiv.org/abs/2510.22946](https://arxiv.org/abs/2510.22946)
- DreamLLM:Â [https://arxiv.org/abs/2309.11499](https://arxiv.org/abs/2309.11499)
- X-Omni:Â [https://arxiv.org/abs/2507.22058](https://arxiv.org/abs/2507.22058)
- Ming-flash-omni-Preview:Â [https://huggingface.co/inclusionAI/Ming-flash-omni-Preview](https://huggingface.co/inclusionAI/Ming-flash-omni-Preview)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## ä¹¦ç± Book

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E4%B9%A6%E7%B1%8D-book)

1. [ã€Šå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼šä»ç†è®ºåˆ°å®è·µã€‹](https://intro-llm.github.io/)
2. [ã€Šå¤§è¯­è¨€æ¨¡å‹ã€‹](https://llmbook-zh.github.io/)
3. [ã€ŠåŠ¨æ‰‹å­¦å¤§æ¨¡å‹Dive into LLMsã€‹](https://github.com/Lordog/dive-into-llms)
4. [ã€ŠåŠ¨æ‰‹åšAI Agentã€‹](https://book.douban.com/subject/36884058/)
5. [ã€ŠBuild a Large Language Model (From Scratch)ã€‹](https://github.com/rasbt/LLMs-from-scratch)
6. [ã€Šå¤šæ¨¡æ€å¤§æ¨¡å‹ã€‹](https://github.com/HCPLab-SYSU/Book-of-MLM)
7. [ã€ŠGenerative AI Handbook: A Roadmap for Learning Resourcesã€‹](https://genai-handbook.github.io/)
8. [ã€ŠUnderstanding Deep Learningã€‹](https://udlbook.github.io/udlbook/)
9. [ã€ŠIllustrated book to learn about Transformers & LLMsã€‹](https://www.reddit.com/r/MachineLearning/comments/1ew1hws/p_illustrated_book_to_learn_about_transformers/)
10. [ã€ŠBuilding LLMs for Production: Enhancing LLM Abilities and Reliability with Prompting, Fine-Tuning, and RAGã€‹](https://www.amazon.com/Building-LLMs-Production-Reliability-Fine-Tuning/dp/B0D4FFPFW8?crid=7OAXELUKGJE4&dib=eyJ2IjoiMSJ9.Qr3e3VSH8LSo_j1M7sV7GfS01q_W1LDYd2uGlvGJ8CW-t4DTlng6bSeOlZBryhp6HJN5K1HqWMVVgabU2wz2i9yLpy_AuaZN-raAEbenKx2NHtzZA3A4k-N7GpnldF1baCarA_V1CRF-aCdc9_3WSX7SaEzmpyDv22TTyltcKT74HAb2KiQqBGLhQS3cEAnzChcqGa1Xp-XhbMnplVwT7xZLApE3tGLhDOgi5GmSi9w.8SY_4NBEkm68YF4GwhDnz0r81ZB1d8jr-gK9IMJE5AE&dib_tag=se&keywords=building+llms+for+production&qid=1716376414&sprefix=building+llms+for+production,aps,101&sr=8-1&linkCode=sl1&tag=whatsai06-20&linkId=ee102fda07a0eb51710fcdd8b8d20c28&language=en_US&ref_=as_li_ss_tl)
11. [ã€Šå¤§å‹è¯­è¨€æ¨¡å‹å®æˆ˜æŒ‡å—ï¼šåº”ç”¨å®è·µä¸åœºæ™¯è½åœ°ã€‹](https://github.com/liucongg/LLMsBook)
12. [ã€ŠHands-On Large Language Modelsã€‹](https://github.com/handsOnLLM/Hands-On-Large-Language-Models)
13. [ã€Šè‡ªç„¶è¯­è¨€å¤„ç†ï¼šå¤§æ¨¡å‹ç†è®ºä¸å®è·µã€‹](https://nlp-book.swufenlp.group/)
14. [ã€ŠåŠ¨æ‰‹å­¦å¼ºåŒ–å­¦ä¹ ã€‹](https://hrl.boyuai.com/)
15. [ã€Šé¢å‘å¼€å‘è€…çš„LLMå…¥é—¨æ•™ç¨‹ã€‹](https://datawhalechina.github.io/llm-cookbook/#/)
16. [ã€Šå¤§æ¨¡å‹åŸºç¡€ã€‹](https://github.com/ZJU-LLMs/Foundations-of-LLMs)
17. [Taming LLMs: A Practical Guide to LLM Pitfalls with Open Source Software](https://www.tamingllms.com/)
18. [Foundations of Large Language Models](https://arxiv.org/abs/2501.09223)
19. [Textbook on reinforcement learning from human feedback](https://github.com/natolambert/rlhf-book)
20. [ã€Šå¤§æ¨¡å‹ç®—æ³•ï¼šå¼ºåŒ–å­¦ä¹ ã€å¾®è°ƒä¸å¯¹é½ã€‹](https://book.douban.com/subject/37331056/)
21. [ã€ŠThe Smol Training Playbook: The Secrets to Building World-Class LLMsã€‹](https://github.com/WangRongsheng/awesome-LLM-resources/blob/main/books/the-smol-training-playbook-the-secrets-to-building-world-class-llms.pdf)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## è¯¾ç¨‹ Course

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E8%AF%BE%E7%A8%8B-course)

> [LLM Resources Hub](https://llmresourceshub.vercel.app/)

1. [æ–¯å¦ç¦ CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/)
2. [å´æ©è¾¾: Generative AI for Everyone](https://www.deeplearning.ai/courses/generative-ai-for-everyone/)
3. [å´æ©è¾¾: LLM series of courses](https://learn.deeplearning.ai/)
4. [ACL 2023 Tutorial: Retrieval-based Language Models and Applications](https://acl2023-retrieval-lm.github.io/)
5. [llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.](https://github.com/mlabonne/llm-course)
6. [å¾®è½¯: Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners)
7. [å¾®è½¯: State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A)
8. [HuggingFace NLP Course](https://huggingface.co/learn/nlp-course/chapter1/1)
9. [æ¸…å NLP åˆ˜çŸ¥è¿œå›¢é˜Ÿå¤§æ¨¡å‹å…¬å¼€è¯¾](https://www.bilibili.com/video/BV1UG411p7zv/?vd_source=c739db1ebdd361d47af5a0b8497417db)
10. [æ–¯å¦ç¦ CS25: Transformers United V4](https://web.stanford.edu/class/cs25/)
11. [æ–¯å¦ç¦ CS324: Large Language Models](https://stanford-cs324.github.io/winter2022/)
12. [æ™®æ—æ–¯é¡¿ COS 597G (Fall 2022): Understanding Large Language Models](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)
13. [çº¦ç¿°éœæ™®é‡‘æ–¯ CS 601.471/671 NLP: Self-supervised Models](https://self-supervised.cs.jhu.edu/sp2023/index.html)
14. [æå®æ¯… GenAIè¯¾ç¨‹](https://www.youtube.com/watch?v=yiY4nPOzJEg&list=PLJV_el3uVTsOePyfmkfivYZ7Rqr2nMk3W)
15. [openai-cookbook](https://github.com/openai/openai-cookbook): Examples and guides for using the OpenAI API.
16. [Hands on llms](https://github.com/iusztinpaul/hands-on-llms): Learn about LLM, LLMOps, and vector DBS for free by designing, training, and deploying a real-time financial advisor LLM system.
17. [æ»‘é“å¢å¤§å­¦ CS 886: Recent Advances on Foundation Models](https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/)
18. [Mistral: Getting Started with Mistral](https://www.deeplearning.ai/short-courses/getting-started-with-mistral/)
19. [æ–¯å¦ç¦ CS25: Transformers United V4](https://web.stanford.edu/class/cs25/)
20. [Coursera: Chatgpt åº”ç”¨æç¤ºå·¥ç¨‹](https://www.coursera.org/learn/prompt-engineering)
21. [LangGPT](https://github.com/langgptai/LangGPT): Empowering everyone to become a prompt expert!
22. [mistralai-cookbook](https://github.com/mistralai/cookbook)
23. [Introduction to Generative AI 2024 Spring](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)
24. [build nanoGPT](https://github.com/karpathy/build-nanogpt): Video+code lecture on building nanoGPT from scratch.
25. [LLM101n](https://github.com/karpathy/LLM101n): Let's build a Storyteller.
26. [Knowledge Graphs for RAG](https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/)
27. [LLMs From Scratch (Datawhale Version)](https://github.com/datawhalechina/llms-from-scratch-cn)
28. [OpenRAG](https://openrag.notion.site/Open-RAG-c41b2a4dcdea4527a7c1cd998e763595)
29. [é€šå¾€AGIä¹‹è·¯](https://waytoagi.feishu.cn/wiki/QPe5w5g7UisbEkkow8XcDmOpn8e)
30. [Andrej Karpathy - Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
31. [Interactive visualization of Transformer](https://poloclub.github.io/transformer-explainer/)
32. [andysingal/llm-course](https://github.com/andysingal/llm-course)
33. [LM-class](https://lm-class.org/lectures)
34. [Google Advanced: Generative AI for Developers Learning Path](https://www.cloudskillsboost.google/paths/183)
35. [Anthropicsï¼šPrompt Engineering Interactive Tutorial](https://github.com/anthropics/courses/tree/master/prompt_engineering_interactive_tutorial/Anthropic%201P)
36. [LLMsBook](https://github.com/liucongg/LLMsBook)
37. [Large Language Model Agents](https://llmagents-learning.org/f24)
38. [Cohere LLM University](https://cohere.com/llmu)
39. [LLMs and Transformers](https://www.ambujtewari.com/LLM-fall2024/)
40. [Smol Vision](https://github.com/merveenoyan/smol-vision): Recipes for shrinking, optimizing, customizing cutting edge vision models.
41. [Multimodal RAG: Chat with Videos](https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/)
42. [LLMs Interview Note](https://github.com/wdndev/llm_interview_note)
43. [RAG++ : From POC to production](https://www.wandb.courses/courses/rag-in-production): Advanced RAG course.
44. [Weights & Biases AI Academy](https://www.wandb.courses/pages/w-b-courses): Finetuning, building with LLMs, Structured outputs and more LLM courses.
45. [Prompt Engineering & AI tutorials & Resources](https://promptengineering.org/)
46. [Learn RAG From Scratch â€“ Python AI Tutorial from a LangChain Engineer](https://www.youtube.com/watch?v=sVcwVQRHIc8)
47. [LLM Evaluation: A Complete Course](https://www.comet.com/site/llm-course/)
48. [HuggingFace Learn](https://huggingface.co/learn)
49. [Andrej Karpathy: Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI)
50. [LLMæŠ€æœ¯ç§‘æ™®](https://github.com/karminski/one-small-step)
51. [CS25: Transformers United V5](https://web.stanford.edu/class/cs25/)
52. [RAG_Techniques](https://github.com/NirDiamant/RAG_Techniques): This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.
53. [100+ LLM & RL Algorithm Maps | åŸåˆ› LLM / RL 100+åŸç†å›¾](https://github.com/changyeyu/LLM-RL-Visualized)
54. [Reinforcement Learning of Large Language Models](https://ernestryu.com/courses/RL-LLM.html)
55. [NanoChat](https://github.com/karpathy/nanochat): The best ChatGPT that $100 can buy.

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## æ•™ç¨‹ Tutorial

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%95%99%E7%A8%8B-tutorial)

1. [åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘](https://datawhalechina.github.io/llm-universe/#/)
2. [AIå¼€å‘è€…é¢‘é“](https://techdiylife.github.io/blog/blog_list.html)
3. [Bç«™ï¼šäº”é‡Œå¢©èŒ¶ç¤¾](https://space.bilibili.com/615957867/?spm_id_from=333.999.0.0)
4. [Bç«™ï¼šæœ¨ç¾½Cheney](https://space.bilibili.com/3537113897241540/?spm_id_from=333.999.0.0)
5. [YTBï¼šAI Anytime](https://www.youtube.com/channel/UC-zVytOQB62OwMhKRi0TDvg)
6. [Bç«™ï¼šæ¼†å¦®å¦®](https://space.bilibili.com/1262370256/?spm_id_from=333.999.0.0)
7. [Prompt Engineering Guide](https://www.promptingguide.ai/)
8. [YTB: AIè¶…å…ƒåŸŸ](https://www.youtube.com/@AIsuperdomain)
9. [Bç«™ï¼šTechBeatäººå·¥æ™ºèƒ½ç¤¾åŒº](https://space.bilibili.com/209732435)
10. [Bç«™ï¼šé»„ç›Šè´º](https://space.bilibili.com/322961825)
11. [Bç«™ï¼šæ·±åº¦å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†](https://space.bilibili.com/507524288)
12. [LLM Visualization](https://bbycroft.net/llm)
13. [çŸ¥ä¹: åŸçŸ³äººç±»](https://www.zhihu.com/people/zhang-shi-tou-88-98/posts)
14. [Bç«™ï¼šå°é»‘é»‘è®²AI](https://space.bilibili.com/1963375439/?spm_id_from=333.999.0.0)
15. [Bç«™ï¼šé¢å£çš„è½¦è¾†å·¥ç¨‹å¸ˆ](https://space.bilibili.com/669720247/?spm_id_from=333.999.0.0)
16. [Bç«™ï¼šAIè€å…µæ–‡å“²](https://space.bilibili.com/472543316/?spm_id_from=333.999.0.0)
17. [Large Language Models (LLMs) with Colab notebooks](https://mlabonne.github.io/blog/)
18. [YTBï¼šIBM Technology](https://www.youtube.com/@IBMTechnology)
19. [YTB: Unify Reading Paper Group](https://www.youtube.com/playlist?list=PLwNuX3xB_tv91QvDXlW2TjrLGHW51uMul)
20. [Chip Huyen](https://huyenchip.com/blog/)
21. [How Much VRAM](https://github.com/AlexBodner/How_Much_VRAM)
22. [Blog: ç§‘å­¦ç©ºé—´ï¼ˆè‹å‰‘æ—ï¼‰](https://kexue.fm/)
23. [YTB: Hyung Won Chung](https://www.youtube.com/watch?v=dbo3kNKPaUA)
24. [Blog: Tejaswi kashyap](https://medium.com/@tejaswi_kashyap)
25. [Blog: å°æ˜‡çš„åšå®¢](https://xiaosheng.blog/)
26. [çŸ¥ä¹: ybq](https://www.zhihu.com/people/ybq-29-32/posts)
27. [W&B articles](https://wandb.ai/fully-connected)
28. [Huggingface Blog](https://huggingface.co/blog/zh)
29. [Blog: GbyAI](https://gby.ai/)
30. [Blog: mlabonne](https://mlabonne.github.io/blog/)
31. [LLM-Action](https://github.com/liguodongiot/llm-action)
32. [Blog: Lilâ€™Log (OponAI)](https://lilianweng.github.io/)
33. [Bç«™: æ¯›ç‰ä»](https://space.bilibili.com/3546823125895398)
34. [AI-Guide-and-Demos](https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN)
35. [cnblog: ç¬¬ä¸ƒå­](https://www.cnblogs.com/theseventhson)
36. [Implementation of all RAG techniques in a simpler way.](https://github.com/FareedKhan-dev/all-rag-techniques)
37. [Theoretical Machine Learning: A Handbook for Everyone](https://www.tengjiaye.com/mlbook.html)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## è®ºæ–‡ Paper

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E8%AE%BA%E6%96%87-paper)

Note

ğŸ¤[Huggingface Daily Papers](https://huggingface.co/papers)ã€[Cool Papers](https://papers.cool/)ã€[ML Papers Explained](https://github.com/dair-ai/ML-Papers-Explained)

1. [Hermes-3-Technical-Report](https://nousresearch.com/wp-content/uploads/2024/08/Hermes-3-Technical-Report.pdf)
2. [The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783)
3. [Qwen Technical Report](https://arxiv.org/abs/2309.16609)
4. [Qwen2 Technical Report](https://arxiv.org/abs/2407.10671)
5. [Qwen2-vl Technical Report](https://arxiv.org/abs/2409.12191)
6. [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954)
7. [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/abs/2405.04434)
8. [Baichuan 2: Open Large-scale Language Models](https://arxiv.org/abs/2309.10305)
9. [DataComp-LM: In search of the next generation of training sets for language models](https://arxiv.org/abs/2406.11794)
10. [OLMo: Accelerating the Science of Language Models](https://arxiv.org/abs/2402.00838)
11. [MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series](https://arxiv.org/abs/2405.19327)
12. [Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model](https://arxiv.org/abs/2404.04167)
13. [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219)
14. [Jamba-1.5: Hybrid Transformer-Mamba Models at Scale](https://arxiv.org/abs/2408.12570v1)
15. [Jamba: A Hybrid Transformer-Mamba Language Model](https://arxiv.org/abs/2403.19887)
16. [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)
17. [Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models](https://arxiv.org/abs/2408.02085)Â `data`
18. [OLMoE: Open Mixture-of-Experts Language Models](https://arxiv.org/abs/2409.02060)
19. [Model Merging Paper](https://huggingface.co/collections/osanseviero/model-merging-65097893623330a3a51ead66)
20. [Baichuan-Omni Technical Report](https://arxiv.org/abs/2410.08565)
21. [1.5-Pints Technical Report: Pretraining in Days, Not Months â€“ Your Language Model Thrives on Quality Data](https://arxiv.org/abs/2408.03506)
22. [Baichuan Alignment Technical Report](https://arxiv.org/abs/2410.14940v1)
23. [Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent](https://arxiv.org/abs/2411.02265)
24. [Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models](https://arxiv.org/abs/2409.17146)
25. [TÃœLU 3: Pushing Frontiers in Open Language Model Post-Training](https://arxiv.org/abs/2411.15124)
26. [Phi-4 Technical Report](https://arxiv.org/abs/2412.08905)
27. [Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling](https://arxiv.org/abs/2412.05271)
28. [Qwen2.5 Technical Report](https://arxiv.org/abs/2412.15115)
29. [YuLan-Mini: An Open Data-efficient Language Model](https://arxiv.org/abs/2412.17743)
30. [An Introduction to Vision-Language Modeling](https://arxiv.org/abs/2405.17247)
31. [DeepSeek V3 Technical Report](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/docs/DeepSeek_V3.pdf)
32. [2 OLMo 2 Furious](https://arxiv.org/abs/2501.00656)
33. [Yi-Lightning Technical Report](https://arxiv.org/abs/2412.01253)
34. [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://github.com/deepseek-ai/DeepSeek-R1)
35. [KIMI K1.5](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/docs/Kimi_k1.5.pdf)
36. [Eagle 2: Building Post-Training Data Strategies from Scratch for Frontier Vision-Language Models](https://arxiv.org/abs/2501.14818)
37. [Qwen2.5-VL Technical Report](https://arxiv.org/abs/2502.13923)
38. [Baichuan-M1: Pushing the Medical Capability of Large Language Models](https://arxiv.org/abs/2502.12671)
39. [Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining](https://arxiv.org/abs/2503.04715)
40. [SkyLadder: Better and Faster Pretraining via Context Window Scheduling](https://arxiv.org/abs/2503.15450)
41. [Qwen2.5-Omni technical report](https://github.com/QwenLM/Qwen2.5-Omni/blob/main/assets/Qwen2.5_Omni.pdf)
42. [Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without Premium GPUs](https://arxiv.org/abs/2503.05139)
43. [Gemma 3 Technical Report](https://arxiv.org/abs/2503.19786)
44. [Open-Qwen2VL: Compute-Efficient Pre-Training of Fully-Open Multimodal LLMs on Academic Resources](https://arxiv.org/abs/2504.00595)
45. [Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs](https://arxiv.org/abs/2504.07866)
46. [MiMo: Unlocking the Reasoning Potential of Language Model â€“ From Pretraining to Posttraining](https://github.com/XiaomiMiMo/MiMo/blob/main/MiMo-7B-Technical-Report.pdf)
47. [Phi-4 Technical Report](https://arxiv.org/abs/2412.08905)
48. [Llama-Nemotron: Efficient Reasoning Models](https://arxiv.org/abs/2505.00949)
49. [Qwen3 Technical Report](https://github.com/QwenLM/Qwen3/blob/main/Qwen3_Technical_Report.pdf)
50. [MiMo-VL Technical Report](https://arxiv.org/abs/2506.03569v1)
51. [ERNIE Technical Report](https://github.com/WangRongsheng/awesome-LLM-resources/blob/main/docs/ERNIE_Technical_Report_compressed.pdf)
52. [Kwai Keye-VL Technical Report](https://arxiv.org/abs/2507.01949)
53. [Kimi K2 Technical Report](https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf)
54. [KAT-V1: Kwai-AutoThink Technical Report](https://arxiv.org/abs/2507.08297v3)
55. [Step3](https://github.com/stepfun-ai/Step3)
56. [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
57. [LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training](https://arxiv.org/abs/2509.23661)Â `[85M-Midtraining Data](https://huggingface.co/datasets/mvp-lab/LLaVA-OneVision-1.5-Mid-Training-85M)`Â `[22M Instruct Data](https://huggingface.co/datasets/mvp-lab/LLaVA-OneVision-1.5-Instruct-Data)`

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## ç¤¾åŒº Community

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E7%A4%BE%E5%8C%BA-community)

1. [é­”ä¹ç¤¾åŒº](https://modelers.cn/)
2. [HuggingFace](https://huggingface.co/)
3. [ModelScope](https://modelscope.cn/)
4. [WiseModel](https://www.wisemodel.cn/)
5. [OpenCSG](https://opencsg.com/)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## æ¨¡å‹ä¸Šä¸‹æ–‡åè®® MCP

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%8D%8F%E8%AE%AE-mcp)

1. [MCPæ˜¯å•¥ï¼ŸæŠ€æœ¯åŸç†æ˜¯ä»€ä¹ˆï¼Ÿä¸€ä¸ªè§†é¢‘ææ‡‚MCPçš„ä¸€åˆ‡ã€‚Windowsç³»ç»Ÿé…ç½®MCPï¼ŒCursor,Cline ä½¿ç”¨MCP](https://www.youtube.com/watch?v=McNRkd5CxFY)
2. [MCPæ˜¯ä»€ä¹ˆï¼Ÿä¸ºå•¥æ˜¯ä¸‹ä¸€ä»£AIæ ‡å‡†ï¼ŸMCPåŸç†+å¼€å‘å®æˆ˜ï¼åœ¨Cursorã€Claudeã€Clineä¸­ä½¿ç”¨MCPï¼Œè®©AIçœŸæ­£è‡ªåŠ¨åŒ–ï¼](https://www.youtube.com/watch?v=jGVsLeDxtQY)
3. [ä»é›¶ç¼–å†™MCPå¹¶å‘å¸ƒä¸Šçº¿ï¼Œè¶…ç®€å•ï¼æ‰‹æŠŠæ‰‹æ•™ç¨‹](https://www.youtube.com/watch?v=a3U-JrFkA9s)

MCPå·¥å…·èšåˆï¼š

1. [smithery.ai](https://smithery.ai/)
2. [mcp.so](https://mcp.so/)
3. [modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)
4. [mcp.ad](https://mcp.ad/)
5. [pulsemcp.com](https://www.pulsemcp.com/)
6. [awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers)
7. [glama.ai](https://glama.ai/mcp/servers)
8. [mcp.composio.dev](https://mcp.composio.dev/)
9. [awesome-mcp-list](https://github.com/MobinX/awesome-mcp-list)
10. [mcpo](https://github.com/open-webui/mcpo)
11. [FastMCP](https://github.com/jlowin/fastmcp)
12. [sharemcp.cn](https://sharemcp.cn/)
13. [mcpstore.co](https://mcpstore.co/)
14. [FastAPI-MCP](https://github.com/tadata-org/fastapi_mcp)
15. [modelscope/mcp](https://modelscope.cn/mcp)
16. [mcpm.sh](https://github.com/pathintegral-institute/mcpm.sh)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## æ¨ç† Open o1

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%8E%A8%E7%90%86-open-o1)

Note

å¼€æ”¾çš„æŠ€æœ¯æ˜¯æˆ‘ä»¬æ°¸æ’çš„è¿½æ±‚

1. [https://github.com/atfortes/Awesome-LLM-Reasoning](https://github.com/atfortes/Awesome-LLM-Reasoning)
2. [https://github.com/hijkzzz/Awesome-LLM-Strawberry](https://github.com/hijkzzz/Awesome-LLM-Strawberry)
3. [https://github.com/wjn1996/Awesome-LLM-Reasoning-Openai-o1-Survey](https://github.com/wjn1996/Awesome-LLM-Reasoning-Openai-o1-Survey)
4. [https://github.com/srush/awesome-o1](https://github.com/srush/awesome-o1)
5. [https://github.com/open-thought/system-2-research](https://github.com/open-thought/system-2-research)
6. [ninehills/blog#121](https://github.com/ninehills/blog/issues/121)
7. [https://github.com/OpenSource-O1/Open-O1](https://github.com/OpenSource-O1/Open-O1)
8. [https://github.com/GAIR-NLP/O1-Journey](https://github.com/GAIR-NLP/O1-Journey)
9. [https://github.com/marlaman/show-me](https://github.com/marlaman/show-me)
10. [https://github.com/bklieger-groq/g1](https://github.com/bklieger-groq/g1)
11. [https://github.com/Jaimboh/Llamaberry-Chain-of-Thought-Reasoning-in-AI](https://github.com/Jaimboh/Llamaberry-Chain-of-Thought-Reasoning-in-AI)
12. [https://github.com/pseudotensor/open-strawberry](https://github.com/pseudotensor/open-strawberry)
13. [https://huggingface.co/collections/peakji/steiner-preview-6712c6987110ce932a44e9a6](https://huggingface.co/collections/peakji/steiner-preview-6712c6987110ce932a44e9a6)
14. [https://github.com/SimpleBerry/LLaMA-O1](https://github.com/SimpleBerry/LLaMA-O1)
15. [https://huggingface.co/collections/Skywork/skywork-o1-open-67453df58e12f6c3934738d0](https://huggingface.co/collections/Skywork/skywork-o1-open-67453df58e12f6c3934738d0)
16. [https://huggingface.co/collections/Qwen/qwq-674762b79b75eac01735070a](https://huggingface.co/collections/Qwen/qwq-674762b79b75eac01735070a)
17. [https://github.com/SkyworkAI/skywork-o1-prm-inference](https://github.com/SkyworkAI/skywork-o1-prm-inference)
18. [https://github.com/RifleZhang/LLaVA-Reasoner-DPO](https://github.com/RifleZhang/LLaVA-Reasoner-DPO)
19. [https://github.com/ADaM-BJTU](https://github.com/ADaM-BJTU)
20. [https://github.com/ADaM-BJTU/OpenRFT](https://github.com/ADaM-BJTU/OpenRFT)
21. [https://github.com/RUCAIBox/Slow_Thinking_with_LLMs](https://github.com/RUCAIBox/Slow_Thinking_with_LLMs)
22. [https://github.com/richards199999/Thinking-Claude](https://github.com/richards199999/Thinking-Claude)
23. [https://huggingface.co/AGI-0/Art-v0-3B](https://huggingface.co/AGI-0/Art-v0-3B)
24. [https://huggingface.co/deepseek-ai/DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)
25. [https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero](https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero)
26. [https://github.com/huggingface/open-r1](https://github.com/huggingface/open-r1)
27. [https://github.com/hkust-nlp/simpleRL-reason](https://github.com/hkust-nlp/simpleRL-reason)
28. [https://github.com/Jiayi-Pan/TinyZero](https://github.com/Jiayi-Pan/TinyZero)
29. [https://github.com/baichuan-inc/Baichuan-M1-14B](https://github.com/baichuan-inc/Baichuan-M1-14B)
30. [https://github.com/EvolvingLMMs-Lab/open-r1-multimodal](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal)
31. [https://github.com/open-thoughts/open-thoughts](https://github.com/open-thoughts/open-thoughts)
32. Mini-R1:Â [https://www.philschmid.de/mini-deepseek-r1](https://www.philschmid.de/mini-deepseek-r1)
33. LLaMA-Berry:Â [https://arxiv.org/abs/2410.02884](https://arxiv.org/abs/2410.02884)
34. MCTS-DPO:Â [https://arxiv.org/abs/2405.00451](https://arxiv.org/abs/2405.00451)
35. OpenR:Â [https://github.com/openreasoner/openr](https://github.com/openreasoner/openr)
36. [https://arxiv.org/abs/2410.02725](https://arxiv.org/abs/2410.02725)
37. LLaVA-o1:Â [https://arxiv.org/abs/2411.10440](https://arxiv.org/abs/2411.10440)
38. Marco-o1:Â [https://arxiv.org/abs/2411.14405](https://arxiv.org/abs/2411.14405)
39. OpenAI o1 report:Â [https://openai.com/index/deliberative-alignment](https://openai.com/index/deliberative-alignment)
40. DRT-o1:Â [https://github.com/krystalan/DRT-o1](https://github.com/krystalan/DRT-o1)
41. Virgoï¼š[https://arxiv.org/abs/2501.01904](https://arxiv.org/abs/2501.01904)
42. HuatuoGPT-o1ï¼š[https://arxiv.org/abs/2412.18925](https://arxiv.org/abs/2412.18925)
43. o1 roadmapï¼š[https://arxiv.org/abs/2412.14135](https://arxiv.org/abs/2412.14135)
44. Mulberryï¼š[https://arxiv.org/abs/2412.18319](https://arxiv.org/abs/2412.18319)
45. [https://arxiv.org/abs/2412.09413](https://arxiv.org/abs/2412.09413)
46. [https://arxiv.org/abs/2501.02497](https://arxiv.org/abs/2501.02497)
47. Search-o1:[https://arxiv.org/abs/2501.05366v1](https://arxiv.org/abs/2501.05366v1)
48. [https://arxiv.org/abs/2501.18585](https://arxiv.org/abs/2501.18585)
49. [https://github.com/simplescaling/s1](https://github.com/simplescaling/s1)
50. [https://github.com/Deep-Agent/R1-V](https://github.com/Deep-Agent/R1-V)
51. [https://github.com/StarRing2022/R1-Nature](https://github.com/StarRing2022/R1-Nature)
52. [https://github.com/Unakar/Logic-RL](https://github.com/Unakar/Logic-RL)
53. [https://github.com/datawhalechina/unlock-deepseek](https://github.com/datawhalechina/unlock-deepseek)
54. [https://github.com/GAIR-NLP/LIMO](https://github.com/GAIR-NLP/LIMO)
55. [https://github.com/Zeyi-Lin/easy-r1](https://github.com/Zeyi-Lin/easy-r1)
56. [https://github.com/jackfsuia/nanoRLHF/tree/main/examples/r1-v0](https://github.com/jackfsuia/nanoRLHF/tree/main/examples/r1-v0)
57. [https://github.com/FanqingM/R1-Multimodal-Journey](https://github.com/FanqingM/R1-Multimodal-Journey)
58. [https://github.com/dhcode-cpp/X-R1](https://github.com/dhcode-cpp/X-R1)
59. [https://github.com/agentica-project/deepscaler](https://github.com/agentica-project/deepscaler)
60. [https://github.com/ZihanWang314/RAGEN](https://github.com/ZihanWang314/RAGEN)
61. [https://github.com/sail-sg/oat-zero](https://github.com/sail-sg/oat-zero)
62. [https://github.com/TideDra/lmm-r1](https://github.com/TideDra/lmm-r1)
63. [https://github.com/FlagAI-Open/OpenSeek](https://github.com/FlagAI-Open/OpenSeek)
64. [https://github.com/SwanHubX/ascend_r1_turtorial](https://github.com/SwanHubX/ascend_r1_turtorial)
65. [https://github.com/om-ai-lab/VLM-R1](https://github.com/om-ai-lab/VLM-R1)
66. [https://github.com/wizardlancet/diagnosis_zero](https://github.com/wizardlancet/diagnosis_zero)
67. [https://github.com/lsdefine/simple_GRPO](https://github.com/lsdefine/simple_GRPO)
68. [https://github.com/brendanhogan/DeepSeekRL-Extended](https://github.com/brendanhogan/DeepSeekRL-Extended)
69. [https://github.com/Wang-Xiaodong1899/Open-R1-Video](https://github.com/Wang-Xiaodong1899/Open-R1-Video)
70. [https://github.com/lsdefine/simple_GRPO](https://github.com/lsdefine/simple_GRPO)
71. [https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero](https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero)
72. [https://github.com/lucasjinreal/Namo-R1](https://github.com/lucasjinreal/Namo-R1)
73. [https://github.com/hiyouga/EasyR1](https://github.com/hiyouga/EasyR1)
74. [https://github.com/Fancy-MLLM/R1-Onevision](https://github.com/Fancy-MLLM/R1-Onevision)
75. [https://github.com/tulerfeng/Video-R1](https://github.com/tulerfeng/Video-R1)
76. [https://huggingface.co/qihoo360/TinyR1-32B-Preview](https://huggingface.co/qihoo360/TinyR1-32B-Preview)
77. [https://github.com/facebookresearch/swe-rl](https://github.com/facebookresearch/swe-rl)
78. [https://github.com/turningpoint-ai/VisualThinker-R1-Zero](https://github.com/turningpoint-ai/VisualThinker-R1-Zero)
79. [https://github.com/yuyq96/R1-Vision](https://github.com/yuyq96/R1-Vision)
80. [https://github.com/sungatetop/deepseek-r1-vision](https://github.com/sungatetop/deepseek-r1-vision)
81. [https://huggingface.co/qihoo360/Light-R1-32B](https://huggingface.co/qihoo360/Light-R1-32B)
82. [https://github.com/Liuziyu77/Visual-RFT](https://github.com/Liuziyu77/Visual-RFT)
83. [https://github.com/Mohammadjafari80/GSM8K-RLVR](https://github.com/Mohammadjafari80/GSM8K-RLVR)
84. [https://github.com/ModalMinds/MM-EUREKA](https://github.com/ModalMinds/MM-EUREKA)
85. [https://github.com/joey00072/nanoGRPO](https://github.com/joey00072/nanoGRPO)
86. [https://github.com/PeterGriffinJin/Search-R1](https://github.com/PeterGriffinJin/Search-R1)
87. [https://openi.pcl.ac.cn/PCL-Reasoner/GRPO-Training-Suite](https://openi.pcl.ac.cn/PCL-Reasoner/GRPO-Training-Suite)
88. [https://github.com/dvlab-research/Seg-Zero](https://github.com/dvlab-research/Seg-Zero)
89. [https://github.com/HumanMLLM/R1-Omni](https://github.com/HumanMLLM/R1-Omni)
90. [https://github.com/OpenManus/OpenManus-RL](https://github.com/OpenManus/OpenManus-RL)
91. [https://arxiv.org/pdf/2503.07536](https://arxiv.org/pdf/2503.07536)
92. [https://github.com/Osilly/Vision-R1](https://github.com/Osilly/Vision-R1)
93. [https://github.com/LengSicong/MMR1](https://github.com/LengSicong/MMR1)
94. [https://github.com/phonism/CP-Zero](https://github.com/phonism/CP-Zero)
95. [https://github.com/SkyworkAI/Skywork-R1V](https://github.com/SkyworkAI/Skywork-R1V)
96. [https://arxiv.org/abs/2503.13939v1](https://arxiv.org/abs/2503.13939v1)
97. [https://github.com/0russwest0/Agent-R1](https://github.com/0russwest0/Agent-R1)
98. [https://github.com/MetabrainAGI/Awaker2.5-R1](https://github.com/MetabrainAGI/Awaker2.5-R1)
99. [https://github.com/LG-AI-EXAONE/EXAONE-Deep](https://github.com/LG-AI-EXAONE/EXAONE-Deep)
100. [https://github.com/qiufengqijun/open-r1-reprod](https://github.com/qiufengqijun/open-r1-reprod)
101. [https://github.com/SUFE-AIFLM-Lab/Fin-R1](https://github.com/SUFE-AIFLM-Lab/Fin-R1)
102. [https://github.com/sail-sg/understand-r1-zero](https://github.com/sail-sg/understand-r1-zero)
103. [https://github.com/baibizhe/Efficient-R1-VLLM](https://github.com/baibizhe/Efficient-R1-VLLM)
104. [https://github.com/hkust-nlp/simpleRL-reason](https://github.com/hkust-nlp/simpleRL-reason)
105. [https://arxiv.org/abs/2502.19655](https://arxiv.org/abs/2502.19655)
106. [https://arxiv.org/abs/2503.21620v1](https://arxiv.org/abs/2503.21620v1)
107. [https://arxiv.org/abs/2503.16081](https://arxiv.org/abs/2503.16081)
108. [https://github.com/ShadeCloak/ADORA](https://github.com/ShadeCloak/ADORA)
109. [https://github.com/appletea233/Temporal-R1](https://github.com/appletea233/Temporal-R1)
110. [https://github.com/inclusionAI/AReaL](https://github.com/inclusionAI/AReaL)
111. [https://github.com/lzhxmu/CPPO](https://github.com/lzhxmu/CPPO)
112. [https://arxiv.org/abs/2503.23829](https://arxiv.org/abs/2503.23829)
113. [https://github.com/TencentARC/SEED-Bench-R1](https://github.com/TencentARC/SEED-Bench-R1)
114. [https://github.com/McGill-NLP/nano-aha-moment](https://github.com/McGill-NLP/nano-aha-moment)
115. [https://github.com/VLM-RL/Ocean-R1](https://github.com/VLM-RL/Ocean-R1)
116. [https://github.com/OpenGVLab/VideoChat-R1](https://github.com/OpenGVLab/VideoChat-R1)
117. [https://github.com/ByteDance-Seed/Seed-Thinking-v1.5](https://github.com/ByteDance-Seed/Seed-Thinking-v1.5)
118. [https://github.com/SkyworkAI/Skywork-OR1](https://github.com/SkyworkAI/Skywork-OR1)
119. [https://github.com/MoonshotAI/Kimi-VL](https://github.com/MoonshotAI/Kimi-VL)
120. [https://arxiv.org/abs/2504.08600](https://arxiv.org/abs/2504.08600)
121. [https://github.com/ZhangXJ199/TinyLLaVA-Video-R1](https://github.com/ZhangXJ199/TinyLLaVA-Video-R1)
122. [https://arxiv.org/abs/2504.11914](https://arxiv.org/abs/2504.11914)
123. [https://github.com/policy-gradient/GRPO-Zero](https://github.com/policy-gradient/GRPO-Zero)
124. [https://github.com/linkangheng/PR1](https://github.com/linkangheng/PR1)
125. [https://github.com/jiangxinke/Agentic-RAG-R1](https://github.com/jiangxinke/Agentic-RAG-R1)
126. [https://github.com/shangshang-wang/Tina](https://github.com/shangshang-wang/Tina)
127. [https://github.com/aliyun/qwen-dianjin](https://github.com/aliyun/qwen-dianjin)
128. [https://github.com/RAGEN-AI/RAGEN](https://github.com/RAGEN-AI/RAGEN)
129. [https://github.com/XiaomiMiMo/MiMo](https://github.com/XiaomiMiMo/MiMo)
130. [https://github.com/yuanzhoulvpi2017/nano_rl](https://github.com/yuanzhoulvpi2017/nano_rl)
131. [https://huggingface.co/a-m-team/AM-Thinking-v1](https://huggingface.co/a-m-team/AM-Thinking-v1)
132. [https://huggingface.co/Intelligent-Internet/II-Medical-8B](https://huggingface.co/Intelligent-Internet/II-Medical-8B)
133. [https://github.com/CSfufu/Revisual-R1](https://github.com/CSfufu/Revisual-R1)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## æ¨ç† Open o3

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%8E%A8%E7%90%86-open-o3)

1. Mini-o3:Â [https://arxiv.org/abs/2509.07969](https://arxiv.org/abs/2509.07969)
2. Simple-o3:Â [https://arxiv.org/abs/2508.12109](https://arxiv.org/abs/2508.12109)
3. Thyme:Â [https://arxiv.org/abs/2508.11630](https://arxiv.org/abs/2508.11630)
4. Open o3 Video:Â [https://arxiv.org/abs/2510.20579](https://arxiv.org/abs/2510.20579)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## å°è¯­è¨€æ¨¡å‹ Small Language Model

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E5%B0%8F%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-small-language-model)

1. [https://github.com/jiahe7ay/MINI_LLM](https://github.com/jiahe7ay/MINI_LLM)
2. [https://github.com/jingyaogong/minimind](https://github.com/jingyaogong/minimind)
3. [https://github.com/DLLXW/baby-llama2-chinese](https://github.com/DLLXW/baby-llama2-chinese)
4. [https://github.com/charent/ChatLM-mini-Chinese](https://github.com/charent/ChatLM-mini-Chinese)
5. [https://github.com/wdndev/tiny-llm-zh](https://github.com/wdndev/tiny-llm-zh)
6. [https://github.com/Tongjilibo/build_MiniLLM_from_scratch](https://github.com/Tongjilibo/build_MiniLLM_from_scratch)
7. [https://github.com/jzhang38/TinyLlama](https://github.com/jzhang38/TinyLlama)
8. [https://github.com/AI-Study-Han/Zero-Chatgpt](https://github.com/AI-Study-Han/Zero-Chatgpt)
9. [https://github.com/loubnabnl/nanotron-smol-cluster](https://github.com/loubnabnl/nanotron-smol-cluster)Â ([ä½¿ç”¨Cosmopediaè®­ç»ƒcosmo-1b](https://huggingface.co/blog/zh/cosmopedia))
10. [https://github.com/charent/Phi2-mini-Chinese](https://github.com/charent/Phi2-mini-Chinese)
11. [https://github.com/allenai/OLMo](https://github.com/allenai/OLMo)
12. [https://github.com/keeeeenw/MicroLlama](https://github.com/keeeeenw/MicroLlama)
13. [https://github.com/Chinese-Tiny-LLM/Chinese-Tiny-LLM](https://github.com/Chinese-Tiny-LLM/Chinese-Tiny-LLM)
14. [https://github.com/leeguandong/MiniLLaMA3](https://github.com/leeguandong/MiniLLaMA3)
15. [https://github.com/Pints-AI/1.5-Pints](https://github.com/Pints-AI/1.5-Pints)
16. [https://github.com/zhanshijinwat/Steel-LLM](https://github.com/zhanshijinwat/Steel-LLM)
17. [https://github.com/RUC-GSAI/YuLan-Mini](https://github.com/RUC-GSAI/YuLan-Mini)
18. [https://github.com/Om-Alve/smolGPT](https://github.com/Om-Alve/smolGPT)
19. [https://github.com/skyzh/tiny-llm](https://github.com/skyzh/tiny-llm)
20. [https://github.com/qibin0506/Cortex](https://github.com/qibin0506/Cortex)
21. [https://github.com/huggingface/picotron](https://github.com/huggingface/picotron)
22. [https://github.com/Alic-Li/Mini_RWKV_7](https://github.com/Alic-Li/Mini_RWKV_7)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## å°å¤šæ¨¡æ€æ¨¡å‹ Small Vision Language Model

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E5%B0%8F%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B-small-vision-language-model)

1. [https://github.com/jingyaogong/minimind-v](https://github.com/jingyaogong/minimind-v)
2. [https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/train_llava](https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/train_llava)
3. [https://github.com/AI-Study-Han/Zero-Qwen-VL](https://github.com/AI-Study-Han/Zero-Qwen-VL)
4. [https://github.com/Coobiw/MPP-LLaVA](https://github.com/Coobiw/MPP-LLaVA)
5. [https://github.com/qnguyen3/nanoLLaVA](https://github.com/qnguyen3/nanoLLaVA)
6. [https://github.com/TinyLLaVA/TinyLLaVA_Factory](https://github.com/TinyLLaVA/TinyLLaVA_Factory)
7. [https://github.com/ZhangXJ199/TinyLLaVA-Video](https://github.com/ZhangXJ199/TinyLLaVA-Video)
8. [https://github.com/Emericen/tiny-qwen](https://github.com/Emericen/tiny-qwen)
9. [https://github.com/merveenoyan/smol-vision](https://github.com/merveenoyan/smol-vision)
10. [https://github.com/huggingface/nanoVLM](https://github.com/huggingface/nanoVLM)
11. [https://github.com/GeeeekExplorer/nano-vllm](https://github.com/GeeeekExplorer/nano-vllm)
12. [https://github.com/ritabratamaiti/AnyModal](https://github.com/ritabratamaiti/AnyModal)
13. [https://github.com/yujunhuics/Reyes](https://github.com/yujunhuics/Reyes)

**[â†¥ back to top](https://github.com/WangRongsheng/awesome-LLM-resources#Contents)**

## æŠ€å·§ Tips

[](https://github.com/WangRongsheng/awesome-LLM-resources#%E6%8A%80%E5%B7%A7-tips)

1. [What We Learned from a Year of Building with LLMs (Part I)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)
2. [What We Learned from a Year of Building with LLMs (Part II)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii/)
3. [What We Learned from a Year of Building with LLMs (Part III): Strategy](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-iii-strategy/)
4. [è½»æ¾å…¥é—¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰](https://www.bilibili.com/video/BV1pF4m1V7FB/?spm_id_from=333.999.0.0&vd_source=c739db1ebdd361d47af5a0b8497417db)
5. [LLMs for Text Classification: A Guide to Supervised Learning](https://www.striveworks.com/blog/llms-for-text-classification-a-guide-to-supervised-learning)
6. [Unsupervised Text Classification: Categorize Natural Language With LLMs](https://www.striveworks.com/blog/unsupervised-text-classification-how-to-use-llms-to-categorize-natural-language-data)
7. [Text Classification With LLMs: A Roundup of the Best Methods](https://www.striveworks.com/blog/text-classification-with-llms-a-roundup-of-the-best-methods)
8. [LLM Pricing](https://docs.google.com/spreadsheets/d/18GHPEBJzDbICmMStPVkNWA_hQHiWmLcqUdEJA1b4MJM/edit?gid=0#gid=0)
9. [Uncensor any LLM with abliteration](https://huggingface.co/blog/mlabonne/abliteration)
10. [Tiny LLM Universe](https://github.com/datawhalechina/tiny-universe)
11. [Zero-Chatgpt](https://github.com/AI-Study-Han/Zero-Chatgpt)
12. [Zero-Qwen-VL](https://github.com/AI-Study-Han/Zero-Qwen-VL)
13. [finetune-Qwen2-VL](https://github.com/zhangfaen/finetune-Qwen2-VL)
14. [MPP-LLaVA](https://github.com/Coobiw/MPP-LLaVA)
15. [build_MiniLLM_from_scratch](https://github.com/Tongjilibo/build_MiniLLM_from_scratch)
16. [Tiny LLM zh](https://github.com/wdndev/tiny-llm-zh)
17. [MiniMind](https://github.com/jingyaogong/minimind): 3å°æ—¶å®Œå…¨ä»0è®­ç»ƒä¸€ä¸ªä»…æœ‰26Mçš„å°å‚æ•°GPTï¼Œæœ€ä½ä»…éœ€2Gæ˜¾å¡å³å¯æ¨ç†è®­ç»ƒ.
18. [LLM-Travel](https://github.com/Glanvery/LLM-Travel): è‡´åŠ›äºæ·±å…¥ç†è§£ã€æ¢è®¨ä»¥åŠå®ç°ä¸å¤§æ¨¡å‹ç›¸å…³çš„å„ç§æŠ€æœ¯ã€åŸç†å’Œåº”ç”¨
19. [Knowledge distillation: Teaching LLM's with synthetic data](https://wandb.ai/byyoung3/ML_NEWS3/reports/Knowledge-distillation-Teaching-LLM-s-with-synthetic-data--Vmlldzo5MTMyMzA2)
20. [Part 1: Methods for adapting large language models](https://ai.meta.com/blog/adapting-large-language-models-llms/)
21. [Part 2: To fine-tune or not to fine-tune](https://ai.meta.com/blog/when-to-fine-tune-llms-vs-other-techniques/)
22. [Part 3: How to fine-tune: Focus on effective datasets](https://ai.meta.com/blog/how-to-fine-tune-llms-peft-dataset-curation/)
23. [Reader-LM: Small Language Models for Cleaning and Converting HTML to Markdown](https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?nocache=1)
24. [LLMsåº”ç”¨æ„å»ºä¸€å¹´ä¹‹å¿ƒå¾—](https://iangyan.github.io/2024/09/08/building-with-llms-part-1/)
25. [LLMè®­ç»ƒ-pretrain](https://zhuanlan.zhihu.com/p/718354385)
26. [pytorch-llama](https://github.com/hkproj/pytorch-llama): LLaMA 2 implemented from scratch in PyTorch.
27. [Preference Optimization for Vision Language Models with TRL](https://huggingface.co/blog/dpo_vlm)Â ã€[support model](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForVision2Seq)ã€‘
28. [Fine-tuning visual language models using SFTTrainer](https://huggingface.co/blog/vlms)Â ã€[docs](https://huggingface.co/docs/trl/sft_trainer#extending-sfttrainer-for-vision-language-models)ã€‘
29. [A Visual Guide to Mixture of Experts (MoE)](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts)
30. [Role-Playing in Large Language Models like ChatGPT](https://promptengineering.org/role-playing-in-large-language-models-like-chatgpt/)
31. [Distributed Training Guide](https://github.com/LambdaLabsML/distributed-training-guide): Best practices & guides on how to write distributed pytorch training code.
32. [Chat Templates](https://hf-mirror.com/blog/chat-templates)
33. [Top 20+ RAG Interview Questions](https://www.analyticsvidhya.com/blog/2024/04/rag-interview-questions/)
34. [LLM-Dojo å¼€æºå¤§æ¨¡å‹å­¦ä¹ åœºæ‰€ï¼Œä½¿ç”¨ç®€æ´ä¸”æ˜“é˜…è¯»çš„ä»£ç æ„å»ºæ¨¡å‹è®­ç»ƒæ¡†æ¶](https://github.com/mst272/LLM-Dojo)
35. [o1 isnâ€™t a chat model (and thatâ€™s the point)](https://www.latent.space/p/o1-skill-issue)
36. [Beam Searchå¿«é€Ÿç†è§£åŠä»£ç è§£æ](https://www.cnblogs.com/nickchen121/p/15499576.html)
37. [åŸºäº transformers çš„ generate() æ–¹æ³•å®ç°å¤šæ ·åŒ–æ–‡æœ¬ç”Ÿæˆï¼šå‚æ•°å«ä¹‰å’Œç®—æ³•åŸç†è§£è¯»](https://blog.csdn.net/muyao987/article/details/125917234)
38. [The Ultra-Scale Playbook: Training LLMs on GPU Clusters](https://huggingface.co/spaces/nanotron/ultrascale-playbook)
